{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MakeNouns( pathName, fileName, Contents ):\n",
    "#     \"\"\"\n",
    "#     만약 Kkma가 설치 되어 있다면 상관없음 \n",
    "#     없으면 설치 권장 \n",
    "#     \"\"\"\n",
    "#     from konlpy.tag import Kkma\n",
    "#     kkma = Kkma()\n",
    "#     path = pathName + fileName\n",
    "#     df_origin  = pd.read_csv( path + '.csv', index_col=False)\n",
    "#     df = df_origin\n",
    "    \n",
    "#     df['Keyword'] = None  # 초기값 세팅 \n",
    "    \n",
    "#     for idx, sen in tqdm(enumerate(Contents)):\n",
    "#         chge   = re.compile('[가-힣. ]+').findall(sen) # 정규식 1차 처리\n",
    "#         nouns  = kkma.nouns( ' '.join(chge) ) # 띄워쓰기 후 명사 추출  \n",
    "#         df['Keyword'][idx] = nouns\n",
    "        \n",
    "#     fullDstName =  path + '_Keyword.csv'\n",
    "#     SaveFile(df, fullDstName,'w', False, 'utf-8-sig' )    \n",
    "    \n",
    "#     return print('Finish !')\n",
    "\n",
    "\n",
    "# def TotalStr(Bunch):\n",
    "#     \"\"\"\n",
    "#     # 리스트안의 중복된 값의 개수\n",
    "#     string 중복값 생성 \n",
    "#     \"\"\"\n",
    "#     import operator\n",
    "\n",
    "#     oneWords = dict()\n",
    "#     for lst in Bunch:\n",
    "#         try: oneWords[lst] += 1\n",
    "#         except: oneWords[lst]=1\n",
    "\n",
    "#     oneWord = sorted(oneWords.items(),reverse=True, key=operator.itemgetter(1))\n",
    "    \n",
    "#     return oneWord\n",
    "\n",
    "\n",
    "# # 자동화 함수 - 구글드라이버를 통해 진행\n",
    "# def GetConfirmToken(response):\n",
    "#     \"\"\"\n",
    "#     # 토큰 받기 \n",
    "#     \"\"\"\n",
    "#     for key, val in response.cookies.items():\n",
    "#         if key.startswith(\"download_warning\"): #  특정 문자로 시작하는지의 여부\n",
    "#             return val\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def SaveResContent(response, destination ):\n",
    "#     \"\"\"\n",
    "#     한 번에 하나씩 데이터를 읽어 Chunk라는 덩어리를 만든 후  \n",
    "#     Chunk 단위로 트랜잭션 -> chunkSize별로 묶어서 처리\n",
    "#     \"\"\"\n",
    "#     chunkSize = 32768\n",
    "#     with open(destination, \"wb\") as f:\n",
    "#         for chunk in response.iter_content(chunkSize):\n",
    "#             if chunk : \n",
    "#                 f.write(chunk)   \n",
    "\n",
    "# def DownloadFunc(id_, destination):\n",
    "#     \"\"\"\n",
    "#     # 구글 드라이버를 통해 데이터 자동 다운로드 \n",
    "#     # id_ : 아이디 -> 제공 \n",
    "#     # destination : 경로 = pathName\n",
    "#     \"\"\"\n",
    "#     baseUrl = \"https://docs.google.com/uc?export=download\"\n",
    "#     session = requests.Session()\n",
    "#     res   = session.get(baseUrl, params = { 'id' : id_ }, stream = True )\n",
    "#     token = GetConfirmToken(res)\n",
    "#     if token:\n",
    "#         params = { 'id' : id_, 'confirm' : token }\n",
    "#         res    = session.get( baseUrl, params = params, stream = True )\n",
    "#         print(f'성공 : {res}')\n",
    "    \n",
    "#     print('다운로드 시작')    \n",
    "#     baseName = res.headers['Content-Disposition'].split(';')[1].split('filename=')[1].replace('\\\"', '')\n",
    "#     fullFileName = path.join( destination, baseName )\n",
    "#     SaveResContent( res, fullFileName )\n",
    "#     print('진행 중 ')\n",
    "#     return fullFileName\n",
    "\n",
    "\n",
    "\n",
    "# def DownloadFromGoogleDrive(fileId, destination):\n",
    "#     \"\"\"\n",
    "#     # 구글 데이터 다운로드   \n",
    "#     fileId   : id 코드 \n",
    "#     pathName : 다운로드 경로 \n",
    "#     \"\"\"\n",
    "#     cnt = 0 \n",
    "#     filenameList = list()\n",
    "#     os.makedirs(destination, exist_ok = True)\n",
    "#     try:\n",
    "#         if len(fileId) == 33 and type(fileId) == str :\n",
    "#             download_func = partial( DownloadFunc, destination = pathName )\n",
    "#             print('다운로드 진행중!')\n",
    "#             fileName = DownloadFunc( id_ = fileId, destination = pathName )\n",
    "#             print(f'{fileName} 완료!')\n",
    "#             filenameList.append(fileName)   \n",
    "\n",
    "#         elif type(fileId) == list :\n",
    "#             for key in tqdm(fileId):\n",
    "#                 cnt += 1 \n",
    "#                 download_func = partial( DownloadFunc, destination = pathName )\n",
    "#                 print('다운로드 진행중!')\n",
    "#                 fileName = DownloadFunc( id_ = key, destination = pathName )\n",
    "#                 print(f'{cnt}번째 {fileName} 완료!')\n",
    "#                 filenameList.append(fileName)   \n",
    "#                 print('='*60)\n",
    "#         else:\n",
    "#             print(' 33자리 Id 코드가 필요합니다. 확인해 주세요!')    \n",
    "                \n",
    "#     except Exception as err:\n",
    "#         print(f'{err} : 에러 발생')\n",
    "        \n",
    "#     return filenameList\n",
    "\n",
    "\n",
    "# def Unzip(filenameList):\n",
    "#     \"\"\"\n",
    "#     # 압축 해제\n",
    "#     \"\"\"\n",
    "#     zipFileNameList = [ pathName for pathName in filenameList if pathName.endswith('.zip')]\n",
    "#     for file in tqdm(zipFileNameList):\n",
    "#         print(f'{file} 진행중!')\n",
    "#         with zipfile.ZipFile(file) as targetZip:\n",
    "#             destPath = path.splitext(file)[0]\n",
    "#             os.makedirs(destPath, exist_ok=True)\n",
    "#             targetZip.extractall(destPath)\n",
    "#             print(f'{destPath} 완료!')\n",
    "#         print(f'.zip 파일삭제 {os.remove(file)}')      \n",
    "\n",
    "\n",
    "# def SaveFile( df, fullDstName,  Mode, index, encoding ):\n",
    "#     \"\"\"\n",
    "#     df = 데이터 프레임\n",
    "#     Mode = 만약 덮어쓰기가 있다면 a , 그냥 생성 w\n",
    "#     fullDstName =  path + 파일 확장자(확장자 주의 요말)\n",
    "#     index = False\n",
    "#     encoding = 인코딩 \n",
    "#     header -> 덮어쓰기에만 적용\n",
    "#     # 2018, 2019, 2020\n",
    "#     \"\"\"\n",
    "#     if fullDstName.split('.')[1] == 'csv' :\n",
    "#         if Mode == 'a' : \n",
    "#             # 파일 여부 확인 후 생성 \n",
    "#             if not os.path.exists( fullDstName ):\n",
    "#                 df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "#             else: \n",
    "#                 df.to_csv( fullDstName , index = index, mode = 'a', encoding = encoding, header = False ) \n",
    "#         else:\n",
    "#             df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "\n",
    "        \n",
    "#     elif fullDstName.split('.')[1] == 'xlsx' :\n",
    "#         if Mode == 'a' : \n",
    "#             # 파일 여부 확인 후 생성 \n",
    "#             if not os.path.exists( fullDstName ):\n",
    "#                 df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "#             else: \n",
    "#                 df.to_xlsx( fullDstName , index = index, mode = 'a', encoding = encoding, header = False )\n",
    "#         else:\n",
    "#             df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "#     else:\n",
    "#         print('Please check your file path! Only, xlsx and csv can use')\n",
    "\n",
    "\n",
    "\n",
    "# def Main( y, m, d, txt, pathName, fileName):\n",
    "#     \"\"\"\n",
    "#     # 크롤링 메인 함수 - 1일 기준 \n",
    "#     y = Year m = Month, d = Day, txt = Keyword, pathName = 파일 위치, fileName = output 될 메인파일이름 \n",
    "#     output 파일은 이런 형식으로 {name}_{y}-{m}-{d}' \n",
    "#     \"\"\"\n",
    "#     page    = 1\n",
    "#     dic     = {}\n",
    "    \n",
    "#     mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "    \n",
    "#     m = StrDate(m) # Date Type\n",
    "#     d = StrDate(d)\n",
    "        \n",
    "#     Running = True \n",
    "#     while Running:\n",
    "        \n",
    "#         targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "#         Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "#         CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "#         print(targetUrl) \n",
    "#         try:\n",
    "#             Titles, Posts = BasicContents( targetUrl )\n",
    "#         except:\n",
    "#             Titles = 'NaN'\n",
    "#             Posts  = 'NaN'\n",
    "\n",
    "#         date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "        \n",
    "#         dic['Title'] = Titles\n",
    "#         dic['Post']  = Posts\n",
    "#         dic['Date']  = date\n",
    "        \n",
    "#         df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "        \n",
    "#         fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "#         SaveFile(df, fullDstName, 'a', False,  'utf-8-sig') # df, fullDstName,  Mode, index, encoding\n",
    "#         print( '='*20, f'{page}','='*20 )\n",
    "#         page += 10 l\n",
    "        \n",
    "#         #  종료 옵션 \n",
    "#         if page == 4001 :  # Crawling max page 4000!\n",
    "#             Running = False\n",
    "#         elif TitPages == 0 :\n",
    "#             Running = False\n",
    "#         elif page == (TitPages*10)+1:\n",
    "#             Running = False\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, glob, time, math, re\n",
    "import pandas as pd\n",
    "\n",
    "# 크롤링\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFile( df, fullDstName,  Mode, index, encoding ):\n",
    "    \"\"\"\n",
    "    df = 데이터 프레임\n",
    "    Mode = 만약 덮어쓰기가 있다면 a , 그냥 생성 w\n",
    "    fullDstName =  path + 파일 확장자(확장자 주의 요말)\n",
    "    index = False\n",
    "    encoding = 인코딩 \n",
    "    header -> 덮어쓰기에만 적용\n",
    "    # 2018, 2019, 2020\n",
    "    \"\"\"\n",
    "    if fullDstName.split('.')[1] == 'csv' :\n",
    "        if Mode == 'a' : \n",
    "            # 파일 여부 확인 후 생성 \n",
    "            if not os.path.exists( fullDstName ):\n",
    "                df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "            else: \n",
    "                df.to_csv( fullDstName , index = index, mode = 'a', encoding = encoding, header = False ) \n",
    "        else:\n",
    "            df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "\n",
    "        \n",
    "    elif fullDstName.split('.')[1] == 'xlsx' :\n",
    "        if Mode == 'a' : \n",
    "            # 파일 여부 확인 후 생성 \n",
    "            if not os.path.exists( fullDstName ):\n",
    "                df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "            else: \n",
    "                df.to_xlsx( fullDstName , index = index, mode = 'a', encoding = encoding, header = False )\n",
    "        else:\n",
    "            df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "    else:\n",
    "        print('Please check your file path! Only, xlsx and csv can use')\n",
    "\n",
    "        \n",
    "def Soup( targetUrl ):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        str = requests.get( targetUrl , headers={'User-Agent':'Mozilla/5.0'} )\n",
    "    except:\n",
    "        str = requests.get( targetUrl )\n",
    "    soup    = BeautifulSoup( str.content , 'lxml' ) # lxml    \n",
    "    \n",
    "    return soup   \n",
    "\n",
    "    \n",
    "###############################################################################\n",
    "        \n",
    "def PageUrl( txt, y, m, d, page ):\n",
    "    \"\"\"\n",
    "    # Page assignment\n",
    "    from urllib.parse import quote\n",
    "    page = '11 단위 수치정보' -> 11,21,31 이런식 \n",
    "    \"\"\"\n",
    "    keyword    = quote(txt)\n",
    "    mainUrl    = f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}'\n",
    "\n",
    "    if page == 1 :\n",
    "        #  page data\n",
    "        paramUrl  = f'&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&ds={y}.{m}.{d}&de={y}.{m}.{d}&docid=&nso=so%3Ar%2Cp%3Afrom{y}{m}{d}to{y}{m}{d}%2Ca%3Aall&mynews=0&refresh_start=0&related=0'\n",
    "        targetUrl = mainUrl + paramUrl\n",
    "        return targetUrl\n",
    "\n",
    "    else:\n",
    "        # Non-page data\n",
    "        paramUrl  = f'&sm=tab_pge&sort=0&photo=0&field=0&reporter_article=&pd=3&ds={y}.{m}.{d}&de={y}.{m}.{d}&docid=&nso=so:r,p:from{y}{m}{d}to{y}{m}{d},a:all&mynews=0&cluster_rank=32&start={page}&refresh_start=0'\n",
    "        targetUrl = mainUrl + paramUrl\n",
    "        return targetUrl\n",
    "\n",
    "\n",
    "    \n",
    "def BasicContents( targetUrl ):\n",
    "    \"\"\"\n",
    "    언론사 그리고 큐스 타이틀만 가지고 오기 \n",
    "    News address  = targetUrl\n",
    "    \"\"\"\n",
    "    soup    = Soup( targetUrl )\n",
    "\n",
    "    newsTitles = soup.select( '.news .type01 li dt a[title]' )\n",
    "    step       = soup.select( '.news .type01 li dd ._sp_each_source' )\n",
    "    \n",
    "    # 리스트에 담아서 리턴\n",
    "    cmpy = [ tit['title'] for tit in newsTitles ]          # 언론사 \n",
    "    txt  = [ s.text.split('언론사 선정')[0] for s in step] # 뉴스 타이틀\n",
    "    \n",
    "    return cmpy, txt   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MaxPageCunt( targetUrl ):\n",
    "    \"\"\"\n",
    "    import math \n",
    "    # Full viewable page  -> MaxPageCunt( target_url ) \n",
    "    \"\"\" \n",
    "    soup    = Soup( targetUrl )\n",
    "    maxPages = soup.find('div',{'class':'title_desc all_my'}) # Total page  \n",
    "    \n",
    "    if maxPages != None:\n",
    "        maxPages = maxPages.find('span').text.split('/')[1].replace('건','').replace(',','').replace(' ','')\n",
    "        print('maxPages',maxPages )\n",
    "\n",
    "        # The number of items on the current page\n",
    "        CurrPagesStep = soup.find('div',{'class':'title_desc all_my'})\n",
    "        CurrPagesStep = CurrPagesStep.find('span').text.split('/')[0].split('-')[1].replace(' ','').replace(',','')\n",
    "\n",
    "        CurrPagesStep = int( CurrPagesStep )\n",
    "        TitPages      = int( maxPages )/4000   # Total Page -> More than 4000 fix it  \n",
    "\n",
    "        # Page count\n",
    "        if TitPages >= 1 :  # More than 4000  \n",
    "            maxPages = 4000\n",
    "            TitPages = int(int(maxPages)/10)\n",
    "\n",
    "        else: # 4000 or less \n",
    "            TitPages = math.ceil(int(maxPages)/10)\n",
    "        return CurrPagesStep, TitPages \n",
    "    \n",
    "    else:\n",
    "        CurrPagesStep = 0\n",
    "        TitPages      = 0\n",
    "        return CurrPagesStep, TitPages \n",
    "    \n",
    "     \n",
    "def StrDate(num):\n",
    "    \"\"\"\n",
    "    # date type change \n",
    "    \"\"\"\n",
    "    if num >= 10:\n",
    "        num = str(num)\n",
    "    else:\n",
    "        num = \"0\"+str(num)\n",
    "    return num\n",
    "\n",
    "\n",
    "def mkDir(pathName, fileName):\n",
    "    \"\"\"\n",
    "    pathName = 'C:/data/'      # 경로\n",
    "    fileName = '이름'          # 이름 \n",
    "    Save Folder Name = pathName, dirname\n",
    "    \"\"\"\n",
    "    path = pathName + fileName\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        targetDir = glob.glob(path)\n",
    "        print('Folder Created')\n",
    "    else:\n",
    "        targetDir = glob.glob(path)\n",
    "        print('Folder already exist')\n",
    "        \n",
    "    return path   \n",
    "\n",
    "\n",
    "\n",
    "def Main( y, m, d, txt, pathName, fileName):\n",
    "    \"\"\"\n",
    "    # 크롤링 메인 함수 - 1일 기준 \n",
    "    y = Year m = Month, d = Day, txt = Keyword, pathName = 파일 위치, fileName = output 될 메인파일이름 \n",
    "    output 파일은 이런 형식으로 {name}_{y}-{m}-{d}' \n",
    "    \"\"\"\n",
    "    page    = 1\n",
    "    dic     = {}\n",
    "    \n",
    "    mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "    \n",
    "    m = StrDate(m) # Date Type\n",
    "    d = StrDate(d)\n",
    "        \n",
    "    Running = True \n",
    "    while Running:\n",
    "        \n",
    "        targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "        Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "        \n",
    "        subUrl         = SubContents(targetUrl)\n",
    "        for u in subUrl:\n",
    "            dic['SubContent'] = Subtxt(u)\n",
    "        \n",
    "        CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "        print(targetUrl) \n",
    "        try:\n",
    "            Titles, Posts = BasicContents( targetUrl )\n",
    "        except:\n",
    "            Titles = 'NaN'\n",
    "            Posts  = 'NaN'\n",
    "\n",
    "        date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "        \n",
    "        dic['Title'] = Titles\n",
    "        dic['Post']  = Posts\n",
    "        dic['Date']  = date\n",
    "        \n",
    "        df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "        \n",
    "        fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "        SaveFile(df, fullDstName, 'a', False,  'UTF-8') # df, fullDstName,  Mode, index, encoding\n",
    "        print( '='*20, f'{page}','='*20 )\n",
    "        page += 10 \n",
    "        \n",
    "        #  종료 옵션 \n",
    "        if page == 4001 :  # Crawling max page 4000!\n",
    "            Running = False\n",
    "        elif TitPages == 0 :\n",
    "            Running = False\n",
    "        elif page == (TitPages*10)+1:\n",
    "            Running = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def MergeData( pathName, fileName ):\n",
    "    \"\"\"\n",
    "    # 일단위로 저장 된 데이터를 병합 \n",
    "    import pandas as pd\n",
    "    import glob, os\n",
    "    pathName = 'C:/data/' \n",
    "    fileName = '이름'\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    dataList = list()\n",
    "    path = mkDir( pathName, fileName ) # Dir check func if Do not have dir make it!\n",
    "    \n",
    "    for pth in tqdm(glob.glob( path +'/*')):\n",
    "        origin  = pd.read_csv( pth, index_col = False )\n",
    "        cnt = cnt + len(origin)\n",
    "        dataList.append(origin)\n",
    "        \n",
    "    CatList= pd.concat( dataList, axis=0, ignore_index = True )\n",
    "    # data folder dir  Save csv file\n",
    "    fullDstName =  path +'.csv'\n",
    "    SaveFile(CatList, fullDstName,'w', False, 'UTF-8')\n",
    "#     SaveFile(CatList, fullDstName,'w', False, 'utf-8-sig')\n",
    "    newPath = glob.glob(pathName+'/*')\n",
    "    print(cnt)\n",
    "    \n",
    "    return newPath\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "        \n",
    "# def SubContents( targetUrl ):\n",
    "#     \"\"\"\n",
    "#     SubContents\n",
    "#     #News address  = targetUrl\n",
    "#     \"\"\"\n",
    "#     soup    = Soup( targetUrl )\n",
    "#     urlNew  = [i['href'] for i in soup.select( '.news .type01 li dt a')]\n",
    "#     print(urlNew)\n",
    "    \n",
    "#     return urlNew   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def Subtxt( Url ):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     로직이 이상해 -> \n",
    "#     \"\"\"\n",
    "#     box = list()\n",
    "    \n",
    "#     for url in Url:\n",
    "        \n",
    "#         id_result = {'Code': ['content', 'article', 'CmAdContent', 'articleWrap','article_body_content']}\n",
    "#         punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "#         soup    = Soup(url) # func\n",
    "\n",
    "#         for code in id_result['Code']:\n",
    "#             cont    = [re.sub(punc,'',i.text).strip().replace('\\n','') for i in soup.select('#'+code)]\n",
    "#             if len(cont) != 0:\n",
    "#                 print(url)\n",
    "#                 box.append(cont)\n",
    "#                 pass\n",
    "#             elif len(cont) == 0 and not code in id_result['Code'] :\n",
    "#                 print('test', url)\n",
    "                \n",
    "#             elif code in id_result['Code']:\n",
    "#                 pass \n",
    "            \n",
    "#             else : \n",
    "# #                 c= [re.search(r'<.*? id=\"(.*?)\">',i.text) for i in soup.select('#'+code)]\n",
    "#                 print(c)\n",
    "#                 print('missUrl', url)\n",
    "\n",
    "#     return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ###############################################################################\n",
    "\n",
    "\n",
    "# # def Subtxt( targetUrl ):\n",
    "# #     \"\"\"\n",
    "# #     \"\"\"\n",
    "# #     soup    = Soup( targetUrl )\n",
    "# #     cont    = [i.text for i in soup.select('#content')]\n",
    "    \n",
    "# #     return cont  \n",
    "\n",
    "\n",
    "# def Subtxt( Url ):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     로직이 이상해 -> \n",
    "#     \"\"\"\n",
    "#     box = list()\n",
    "    \n",
    "#     for url in Url:\n",
    "        \n",
    "#         id_result = {'Code': ['content', 'article', 'CmAdContent', 'articleWrap','article_body_content']}\n",
    "#         punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "#         soup    = Soup(url) # func\n",
    "\n",
    "#         for code in id_result['Code']:\n",
    "# #             print(code)\n",
    "# #             for i in soup.select('#'+code):\n",
    "# #                 d = re.sub(punc,'',i.text).strip().replace('\\n','') \n",
    "# #                 print(d)\n",
    "#             cont    = [re.sub(punc,'',i.text).strip().replace('\\n','') for i in soup.select('#'+code)]\n",
    "#             if len(cont) != 0:\n",
    "# #                 print(len(cont))\n",
    "#                 box.append(cont)\n",
    "#                 pass\n",
    "# #             else:\n",
    "#             elif code in id_result['Code']:\n",
    "        \n",
    "#                     pass \n",
    "#             else : \n",
    "#                 print('missUrl', url)\n",
    "# #                 if code in id_result['Code']\n",
    "# #                     print('missUrl', url)\n",
    "# #                 return url\n",
    "\n",
    "#     return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 진행코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "d = 1\n",
    "y = 2020\n",
    "\n",
    "pathName = 'C:/TmP/' # 사용자가 원하는 경로\n",
    "fileName     = 'test' \n",
    "txt          = '현대 사회 문제' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetUrl = 'http://yna.kr/AKR20200101039051074?did=1195m'\n",
    "# print(targetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exist\n",
      "['http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374', 'http://yna.kr/AKR20200101009951504?did=1195m', 'https://www.artinsight.co.kr/news/view.php?no=45507', 'http://news1.kr/articles/?3806084', 'http://www.hankookilbo.com/news/npath/202001010720336919?did=NA', 'http://news.maxmovie.com/411055', 'http://news.mt.co.kr/mtview.php?no=2019122013344318125', 'http://www.newscj.com/news/articleView.html?idxno=695916', 'http://www.gndomin.com/news/articleView.html?idxno=228517', 'http://www.hankookilbo.com/news/npath/201912301356359103?did=NA']\n",
      "http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374\n",
      "http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374\n",
      "http://yna.kr/AKR20200101009951504?did=1195m\n",
      "http://news1.kr/articles/?3806084\n",
      "http://news1.kr/articles/?3806084\n",
      "http://news.mt.co.kr/mtview.php?no=2019122013344318125\n",
      "http://www.newscj.com/news/articleView.html?idxno=695916\n",
      "http://www.gndomin.com/news/articleView.html?idxno=228517\n",
      "[['청년들이 한 곳에 모여 자유롭게 의견을 공유하는 공간을 제공하다 창업을 지원하는 등 청년공동체가 눈길을 끈다 이들의 활동은 자연스럽게 지역사회 변화까지 이끌어내며 그야말로 청년문화 순기능의 대표적인 사례이다 \\r대전 유성구 어은동 일원 공유공간협업커뮤니티인 벌집을 찾았다 벌집은 도시에서 일상의 재미와 변화를 만들려 했던 꿈들을 논의하기 위한 공유공간으로 시작됐는데 이를 지속하기 위해 2017년 윙윙이 설립됐다 이제는 커피숍 쉐어하우스 공유주방 소규모 강당 대관은 물론 최근 도시재생사업까지 확장됐다 이곳에서 청년들은 벌로 불린다 청년들이 창업할 수 있도록 지원하는 벌 지역에 문화콘텐츠를 공급하는 벌 쉐어하우스에서 함께 사는 벌 등이 있다 \\r이태호32 도시재생 스타트업 윙윙 대표는 초창기 벌집은 다양한 관심사를 가진 청년들이 모여 의견 아이디어를 나누며 소통하자는 취지로 시작된 공유공간이라며 과거에 비해 현대사회는 관심사나 목적이 없이 청년들이 만나기 어려운데 이곳에서는 목적 없이도 만날 수 있다고 말했다 \\r이태호 대표이어 그는 이 공간에서 만난 청년들이 의견을 나누며 자연스럽게 창업을 꿈꾸고 연결해주는 작업이 이뤄지며 실제 창업으로 이어졌고 나아가 지역사회 문제를 해결하며 가치있는 서비스를 제공하고 있다며 공간이 관계와 재능을 모아 기회를 만드는 선순환 구조인 셈이라고 말했다 \\r특히 청년들과 어은동 주민상인들 간 조화 상생이 눈에 띈다 \\r올해 윙윙은 어은동 뉴딜사업의 현장지원센터를 맡아 도시재생 프로젝트를 진행하고 있다 이 일환으로 도시재생대학을 운영하거나 환경정화활동 어르신 자서전 전시회 청년과 상인들이 함께 참여하는 지역 브랜드인 안녕가게 마을축제인 안녕축제 등 다양한 프로젝트를 진행하며 새로운 변화가 일어나고 있다 \\r이 대표는 마을의 문제를 깊게 들여다 보고 성장을 위해 연결해주는 작업을 하고 있다며 뉴딜사업에 관심이 없던 마을 주민 상인들의 참여도가 점점 높아지며 동네가 발전해가고 있다 청년들은 마을문제 해결 축제기획 마을굿즈 제작 마을여행 기획 등 지역 공동체활동형태의 재능기부를 통해 지역에 대한 관심 애정이 커졌다고 말했다  \\r그러면서 이 대표는 어은동 뉴딜사업이 끝나면 플랫폼을 구조화시켜 다른 지역에도 접목할 계획이라며 청년들이 자유롭게 만나 서로의 고민을 논의하다 보니 창업을 돕고 지역사회 정책과 문화에 기여하는 역할을 하게 됐다고 말했다  김정원 기자'], ['청년들이 한 곳에 모여 자유롭게 의견을 공유하는 공간을 제공하다 창업을 지원하는 등 청년공동체가 눈길을 끈다 이들의 활동은 자연스럽게 지역사회 변화까지 이끌어내며 그야말로 청년문화 순기능의 대표적인 사례이다 \\r대전 유성구 어은동 일원 공유공간협업커뮤니티인 벌집을 찾았다 벌집은 도시에서 일상의 재미와 변화를 만들려 했던 꿈들을 논의하기 위한 공유공간으로 시작됐는데 이를 지속하기 위해 2017년 윙윙이 설립됐다 이제는 커피숍 쉐어하우스 공유주방 소규모 강당 대관은 물론 최근 도시재생사업까지 확장됐다 이곳에서 청년들은 벌로 불린다 청년들이 창업할 수 있도록 지원하는 벌 지역에 문화콘텐츠를 공급하는 벌 쉐어하우스에서 함께 사는 벌 등이 있다 \\r이태호32 도시재생 스타트업 윙윙 대표는 초창기 벌집은 다양한 관심사를 가진 청년들이 모여 의견 아이디어를 나누며 소통하자는 취지로 시작된 공유공간이라며 과거에 비해 현대사회는 관심사나 목적이 없이 청년들이 만나기 어려운데 이곳에서는 목적 없이도 만날 수 있다고 말했다 \\r이태호 대표이어 그는 이 공간에서 만난 청년들이 의견을 나누며 자연스럽게 창업을 꿈꾸고 연결해주는 작업이 이뤄지며 실제 창업으로 이어졌고 나아가 지역사회 문제를 해결하며 가치있는 서비스를 제공하고 있다며 공간이 관계와 재능을 모아 기회를 만드는 선순환 구조인 셈이라고 말했다 \\r특히 청년들과 어은동 주민상인들 간 조화 상생이 눈에 띈다 \\r올해 윙윙은 어은동 뉴딜사업의 현장지원센터를 맡아 도시재생 프로젝트를 진행하고 있다 이 일환으로 도시재생대학을 운영하거나 환경정화활동 어르신 자서전 전시회 청년과 상인들이 함께 참여하는 지역 브랜드인 안녕가게 마을축제인 안녕축제 등 다양한 프로젝트를 진행하며 새로운 변화가 일어나고 있다 \\r이 대표는 마을의 문제를 깊게 들여다 보고 성장을 위해 연결해주는 작업을 하고 있다며 뉴딜사업에 관심이 없던 마을 주민 상인들의 참여도가 점점 높아지며 동네가 발전해가고 있다 청년들은 마을문제 해결 축제기획 마을굿즈 제작 마을여행 기획 등 지역 공동체활동형태의 재능기부를 통해 지역에 대한 관심 애정이 커졌다고 말했다  \\r그러면서 이 대표는 어은동 뉴딜사업이 끝나면 플랫폼을 구조화시켜 다른 지역에도 접목할 계획이라며 청년들이 자유롭게 만나 서로의 고민을 논의하다 보니 창업을 돕고 지역사회 정책과 문화에 기여하는 역할을 하게 됐다고 말했다  김정원 기자'], ['뉴스홈최신기사김정은 경제부문 질타…허리띠 졸라매도 제재봉쇄 돌파해야종합송고시간20200101 1406공유닫기카카오톡에 공유페이스북에 공유트위터에 공유카카오 스토리에 공유페이스북 메신저에 공유네이버 밴드에 공유네이버 블로그에 공유핀터레스트에 공유댓글글자크기조정닫기폰트 1단계 14px폰트 2단계 15px폰트 3단계 16px 기본설정폰트 4단계 17px폰트 5단계 18px폰트 6단계 19px폰트 7단계 20px인쇄박수윤 기자유리한 대외환경 절실하지만 목숨 같은 존엄 팔 수 없어통일부 北 장기 제재 기정사실화…경제가 기본 전선임을 재확인 서울연합뉴스 김동현 박수윤 정빛나 기자  김정은 북한 노동당 위원장이 미국의 대북제재에 따른 경제적 난관을 자력갱생으로 정면 돌파하겠다고 밝혔다북한 노동당 제7기 제5차 전원회의서울연합뉴스 김정은 북한 국무위원장이 지난달 31일 노동당 중앙위원회 본부청사에서 제7기 제5차 전원회의를 지도했다고 1일 조선중앙통신이 보도했다 국내에서만 사용가능 재배포 금지 For Use Only in the Republic of Korea No Redistribution nkphoto@ynacokr 김 위원장은 지난달 28일부터 31일까지 노동당 중앙위원회 본부청사에서 열린 제7기 제5차 전원회의에서 경제 부문을 침체 타성에 젖은 등 강한 어휘로 비판하며 이같이 말했다고 조선중앙통신이 1일 전했다 김 위원장은 허리띠를 졸라매더라도 기어이 자력부강 자력번영하여 나라의 존엄을 지키고 제국주의를 타승하겠다는 것이 우리의 억센 혁명 신념이라고 말문을 열었다광고김정은 곧 머지않아 새 전략무기 목격할 것…미국 시간끌지 마라  연합뉴스 Yonhapnews유튜브로 보기 이는 김 위원장이 집권 초기인 2012년 4월 15일 김일성 주석 100회 생일 경축 열병식에서 우리 인민이 다시는 허리띠를 조이지 않게 하겠다던 발언을 뒤집은 셈이다 그는 경제 상황이 녹록지 않다는 점을 솔직히 인정했다  그는 적과의 치열한 대결은 항상 자체의 역량 강화를 위한 사업을 동반하며 자기를 강하게 만드는 사업이 선행되어야 주동에 서서 승리를 쟁취할 수 있다면서 자력강화의 견지에서 볼 때 국가관리와 경제사업을 비롯한 이여의다른 분야에서 바로잡아야 할 문제가 적지 않다고 꼬집었다 또 자력갱생 자급자족하자고 계속 말하고 있지만 이를 실행하는 우리의 사업은 지난날의 타성에서 탈피하지 못하고 있다면서 국가관리 사업과 경제사업이 자립 자강의 거창한 위업을 견인하고 추동하기에는 불충분하며 대담하게 혁신하지 못하고 침체되어 있다고 지적했다 금속공업 화학공업 전력공업 석탄공업 기계공업 건재공업 철도운수 경공업부문을 열거하며 폐단이 산적됐다고도 비판했다북한 노동당 제7기 제5차 전원회의서울연합뉴스 김정은 북한 국무위원장이 지난달 31일 노동당 중앙위원회 본부청사에서 제7기 제5차 전원회의를 지도했다고 1일 조선중앙통신이 보도했다  국내에서만 사용가능 재배포 금지 For Use Only in the Republic of Korea No Redistribution nkphoto@ynacokr 그러면서 나라의 경제를 재정비하자면 결정적으로 경제사업에 대한 국가의 통일적 지도와 전략적 관리를 실현하기 위한 강한 대책을 세워야 한다고 당부했다 김 위원장은 특히 경제사령부로서의 내각이 자기의 책임을 다하지 못하고 있는 심각한 현 실태를 엄중히 꼬집으면서 내각의 역할을 강조했다 대책으로는 ▲ 사회주의 상업 복원 ▲ 불필요한 절차제도 정리 ▲ 사업능률을 저하하는 요소들 바로잡기 ▲ 전문 건설 역량 확대 강화와 건설장비 현대화 ▲ 사회주의기업책임관리제의 현실성 있는 실시 ▲ 과학농사 ▲ 증산 절약과 질 제고 ▲생태환경 보호와 자연재해 방지 등을 주문했다 김 위원장은 자기 힘을 믿지 못하는 땜때기식 투자 자체의 잠재력에 의거하지 않는 하루살이식 투자는 밑 빠진 독에 물 붓기라며 미래를 내다보면서 전망성 있게 사업하는 것이 혁명을 책임지는 마땅한 태도라고 강조했다경청하는 북한 전원회의 참석자들서울연합뉴스 김정은 북한 국무위원장이 지난달 31일 노동당 중앙위원회 본부청사에서 제7기 제5차 전원회의를 지도했다고 1일 조선중앙통신이 보도했다 사진은 경청하는 참석자들 국내에서만 사용가능 재배포 금지 For Use Only in the Republic of Korea No Redistribution nkphoto@ynacokr 김 위원장은 그러면서 정면돌파를 열쇳말로 제시했다 그는 우리에게 있어서 경제건설에 유리한 대외적 환경이 절실히 필요한 것은 사실이지만 결코 화려한 변신을 바라며 지금껏 목숨처럼 지켜온 존엄을 팔 수는 없다고 말했다 이어 미국과 적대 세력들이 우리가 편하게 살도록 가만두리라는 꿈은 꾸지도 말아야 하며 사회주의 건설의 전진도상에 가로놓인 난관을 오직 자력갱생의 힘으로 정면돌파해야 한다고 말했다 통일부는 이날 배포한 분석자료에서 북한이 장기적 제재 국면을 기정 사실화했다면서 사회주의 건설의 새로운 활로을 위한 정면돌파전 강행을 강조하며 경제가 기본 전선임을 재확인했다고 평가했다 clap@ynacokr저작권자c 연합뉴스 무단 전재재배포 금지20200101 1406 송고김정은경제광고댓글쓰기광고당신이 함께 보면 좋은 기사당신이 좋아할 만한 기사현장 영상영상 기사재생시간0231영상 신규확진 136명 엿새째 100명대…수도권 집중 여전영상 기사재생시간0130영상 짐승이나 할 소리 버럭한 트럼프 왜영상 기사재생시간0116영상 WHO 사무총장 코로나19 마지막 팬데믹 아닐 것…한국도 언급영상 기사재생시간0237영상 전세 40억원 월세 1천만원…최고가 아파트는 어디영상 기사재생시간0136영상 우리 아기 성별은 뭘까…축하파티 열다 그만 대형 산불로영상 기사재생시간0240영상 전공의들 현장 복귀하는 날…의대생 86 의사국시 거부당신이 함께 보면 좋은 영상광고광고핫뉴스아쉬움 가득한 류현진 양키스전 다음엔 잘 던지겠습니다버스비 아끼려 1시간 반 걷던 딸 제주 묻지마 강도살해 청원동해 60대 부부 숨진 채 발견…남편의 몸통은 돌덩이에 눌려마이티 마우스…우주여행 갔던 쥐 근육질돼 돌아왔다12세 여아와 조건만남 후 음란물 촬영시킨 30대 문대통령 안경 안쓰고 국무회의…靑 특별한 이유 사고 낸 음주운전자는 벌금형인데 동승자는 실형 법정17일간 아기 죽음 애도했던 미국 범고래 다시 엄마광고광고많이 본 뉴스종합정치경제사회세계스포츠연예이전다음마스크 시비로 몸싸움 벌인 중년 부부와 고등학생 경찰서행다시 구치소 가는 전광훈 대통령 한마디에 구속…항고할 것버스비 아끼려 1시간 반 걷던 딸 제주 묻지마 강도살해 청원동해 60대 부부 숨진 채 발견…남편의 몸통은 돌덩이에 눌려종합중국 22일간 코로나 환자 0라더니…한국행 승객 5명 확진버스비 아끼려 1시간 반 걷던 딸 제주 묻지마 강도살해 청원홍남기 3기 신도시 내년 7월부터 3만호 사전청약추미애 아들측 카투사 규정 육군과 달라…병가에 문제없어질병관리청 12일 공식 출범…정원 1천476명으로 42 순증종합2보이재명 선별지급 적극 지원해야…훼방 놓을 생각 없다홍남기 3기 신도시 내년 7월부터 3만호 사전청약4층 높이 파도 덮친 공장…부산 산업 현장 곳곳 피해3기 신도시 등 공공분양 중형 면적 최대 50까지 늘린다종합내년 7월부터 하남 교산과천용산 정비창 등 6만채 사전청약카카오게임즈 증거금 58조 중 절반은 증시에 남았다마스크 시비로 몸싸움 벌인 중년 부부와 고등학생 경찰서행다시 구치소 가는 전광훈 대통령 한마디에 구속…항고할 것버스비 아끼려 1시간 반 걷던 딸 제주 묻지마 강도살해 청원동해 60대 부부 숨진 채 발견…남편의 몸통은 돌덩이에 눌려종합여의도뚝섬반포한강공원 밀집구역 오후 2시부터 출입통제종합중국 22일간 코로나 환자 0라더니…한국행 승객 5명 확진밤새 술 마신 日여성…차에 방치된 두 딸 열사병으로 숨져미셸 오바마 남편 창밖으로 밀고 싶을때도…결혼은 인내뉴욕 흑인 복면 질식사 항의 나체 시위WHO 마지막 팬데믹 아닐 것…다음엔 더 잘 준비해야류현진 MLB서 7번째로 한 경기 3피홈런…양키스에 7홈런 헌납임성재 보너스 포함 시즌 수입 72억원…주당 1억 이상 벌었다종합류현진 양키스전서 홈런 3개 맞고 5이닝 5실점…패전은 면해종합아쉬움 가득한 류현진 양키스전 다음엔 잘 던지겠습니다종합바르셀로나 잔류 메시 새 시즌 분홍색 유니폼 모델로 등장블랙페이스 분장 논란 샘 오취리 예능 대한외국인 하차코로나 집단감염 일련정종…일제 찬양 이유로 법인 불허장성규 응급실행에 김정현 아나운서 굿모닝FM 대타 진행배두나공유이준 정우성 제작 넷플릭스 고요의 바다 출연솔로데뷔 에이핑크 김남주 알을 깨고 나온 여전사 표현했죠광고광고에디터스 픽Editors Picks영상영상 기사재생시간0216영상 3기 신도시 등 3만호 사전청약 내년 7월부터 시작영상 기사재생시간0209영상 코로나19 집단감염 2주간 52건…어르신 각별히 주의해야영상 기사재생시간0250이슈 컷 갈 때 가더라도 지금은…BTS 입영열차 시간표는뉴스 초대 질병관리청장 정은경…신설 보건담당 2차관 강도태방역당국 이달 코로나19 상업용 항체치료제 대량 생산 계획정부 거리두기 효과 가시화…재연장 여부 이번 주말께 결정대전협 새비대위 구성…단체행동 재논의…업무복귀 번복될수도집 사지말고 청약하세요 하남 교산과천 등 6만채 사전청약영상 기사재생시간1750Y스페셜 코로나 안전망 역량 입증한 스마트시티광고광고광고댓글 많은 뉴스다시 구치소 가는 전광훈 대통령 한마디에 구속…항고할 것댓글수226마스크 시비로 몸싸움 벌인 중년 부부와 고등학생 경찰서행댓글수117블랙페이스 분장 논란 샘 오취리 예능 대한외국인 하차댓글수42추미애 아들 의혹 수사 관련 사건 보고 받지 않을 것종합댓글수39추미애 아들측 카투사 규정 육군과 달라…병가에 문제없어댓글수36광고뭐하고 놀까흥'], ['홈  지방   강원 신년사 최승준 정선군수 풍요로운 미래 행복한 정선 만들겠다 \\r\\t\\t\\t\\t\\t정선뉴스1 박하림 기자\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t20200101 0700 송고\\t\\t\\t\\t기사보기네티즌의견Tweet인쇄확대축소최승준 전 정선군수 © News1\\xa0존경하는 군민 여러분희망찬 경자년 새해가 밝았습니다새해 아침의 첫 소망을 담아 군민 여러분의 안정과 번영을 빌면서 소망하는 모든 일들이 이루어지는 한 해가 되길 진심으로 기원 드립니다지난 한 해 희망찬 아침 평온한 저녁 행복한 정선을 만들기 위해 군정을 믿고 보내주신 성원과 진심어린 충고는 우리군이 한 단계 도약하는 데 큰 도움이 되었습니다진심으로 감사드리며 올 한 해도 군민 여러분의 깊은 관심과 성원을 부탁드리겠습니다현대사회는 분열과 빈익빈 부익부 현상으로 불평등은 날로 심해지고 불안은 커지며 미래가 보이지 않는다고 합니다지금과 같은 사회 지금과 같은 삶의 방식이 그대로 유지될 수 있다고 생각하는 것은 어찌보면 환상일지도 모릅니다저는 민선 7기 군수로 취임하면서 공감과 소통을 키워드로 삼아 군민이 주인되는 행복한 정선을 만들겠다고 약속했습니다지난해까지는 공감과 소통으로 기틀을 다졌다면 올 한 해는 군민의 기대에 부응할 수 있는 결실을 맺을 수 있도록 모든 역량을 집결해 군정을 이끄는 데 최선의 노력을 다하겠습니다국민소득 3만불 시대에 맞는 복지정책과 행복하고 살기 좋은 농업․농촌 살맛 나는 지역경제를 위해 군정을 펼쳐 나아가겠습니다먼저 앞서가는 복지정책으로 행복한 정선을 만들겠습니다민선 7기 최우선 과제인 무상 또는 1000원으로 누구나 이용할 수 있는 버스완전공영제를 상반기에 본격적으로 실시하고 희망택시 서비스의 불합리한 부분을 개선하고자 공공형 택시를 도입해 교통복지서비스를 전면 개편하겠습니다모든 군민에게 발생하는 각종 사고와 자연재난으로부터 안전하게 생활할 수 있는 전 군민 안심케어 5대 사업과 정선의 미래를 책임질 인재 양성을 위해 무상교육복지 지원을 확대하고 어르신들의 공공 일자리 창출로 안정된 노후생활 정착과 여성의 경제활동 참여 확대 다문화가정의 안정적 정착 지원을 위한 복지정책도 확대해 나아가겠습니다정선군립병원은 낡은 시설의 구조적인 문제해결을 위해 병동 신축과 의료재단을 설립해 정상적으로 운영하겠으며 농어촌 의료서비스 개선사업의 확대로 의료복지서비스의 질을 높여 모든 계층이 행복한 복지 구현을 실현하겠습니다 둘째 행복하고 살기 좋은 농업․농촌을 만들겠습니다농업인구의 감소와 고령화 경기침체로 인한 농산물 소비 위축과 WTO 농업 분야 개발도상국 지위 포기로 농촌의 현실은 날이 갈수록 어려워지고 있지만 농업은 과거나 현재나 미래에도 한 나라의 근간이자 가장 기초가 되는 산업으로 포기할 수 없습니다주민 소득수준과 생활수준을 높이는 일반농산어촌개발 사업과 기업형 농촌육성사업 농촌체험관광 네트워크 허브조성 6차 산업의 기초가 될 농촌융복합화지구 조성사업을 추진해 침체된 농촌에 새로운 활력을 불어넣겠습니다또한 청년 농업인의 영농정착 지원과 농업대학을 통한 전문농업인을 육성하고 품목별 공동선별시스템 및 가공센터구축 농자재 공동구매로 가격인하 마을공동급식지원 확대를 통해 농산물의 명품화와 가격 경쟁력을 확보해 소득증대에 기여해 나가겠습니다안정적인 농산물 판매를 위해 온오프라인 홍보와 더불어 대형유통망과 직거래 유통을 중심으로 안정적인 농산물 판로를 확보토록 하겠습니다셋째 변화하는 관광트랜드에 맞춰 한 번 더 찾고 싶은 문화관광지로 변모시켜 나가겠습니다최근 관광트랜드는 자연․숲 치유 건강․체력관리 뷰티․미용 명상․정신수양 등의 다양한 테마로 구분되는 웰니스 관광으로 변하고 있습니다힐링음악과 음식을 결합한 가리왕산 뮤직페스티벌 개최로 웰니스 관광상품 개발의 가능성을 보았고 정선아리랑과 향토음식 그리고 기 조성된 관광지와 결합한 웰니스 클러스터를 구축해 변화하는 관광트랜드에 맞춰 우리군 신성장 동력으로 발전시켜 나가겠습니다특히 KTX 경강선을 이용하는 관광객을 유치하기 위해 진부역정선5일장 노선에 2층 관광 셔틀버스를 도입하고 SNS 관광 홍보단과 유튜브 홍보 채널을 통합운영하고 ‘보고싶다 정선아’ 브랜드 마케팅을 다양하게 운영해 특색있는 관광홍보마케팅으로 관광객 유치에 최선을 다하겠습니다폐광지역 경제회생을 위해 추진중인 폐광지역 관광자원화 3단계 사업의 신규사업 발굴과 국비를 확보해 관광산업의 전환점이 될 수 있도록 준비해 나가겠습니다올림픽 레거시로 재탄생한 정선아리랑극 ‘아리아라리’ 의 지속적인 업그레이드와 우리군 대표축제인 정선아리랑제는 전문예술감독 선임과 프로그램 개선을 통해 공연과 축제의 완성도를 높이고 아리샘터에 이어 북평 임계지역에도 생활문화센터를 조성해 누구나 이용할 수 있는 지역문화 기반시설을 확충해 나가겠습니다넷째 군민이 살맛나는 지역경제와 지역개발을 이루어 내겠습니다 먼저 약화되는 골목상권 경쟁력 제고를 위한 정선읍 상권르네상스 사업을 주축으로 9개 읍면 5일장에 추진중인 고객센터 신축사업 골목경제 활성화사업 등은 조기에 완료해 활기찬 시장경제를 이끌어 나가겠습니다고한 야생화마을 추리극장 조성사업 사북읍 빛의 거리 조성사업을 정상적으로 추진해 고한․사북지역을 방문하는 카지노 관광객을 시내로 유도해 지역경제 활성화를 도모하겠습니다또한 북평과 사북지역에 230세대의 아파트 신축 협의 농촌중심지 활성화사업 LPG 배관망 구축 및 도시가스설치 지원사업 추진으로 사람들의 온정이 넘치는 도시와 마을로 재탄생 시켜 정주여건을 개선토록 하겠습니다금년 한 해는 감소하는 인구정책에 대해 획기적인 정책 변화를 시도하겠습니다 인구정책 비전을 ‘모든 세대가 살기 좋은 정선 실현’으로 정하고 일자리 창출 복지서비스 향상 인구변화대응 등의 정책목표로 인구 증가에서 인구유지 정책으로 전환해 인구 감소의 전환점이 되는 정책을 추진하겠습니다우리군의 주요 현안사업인 정선관광의 랜드마크가 될 가칭 아라리교 가설을 위한 재원확보와 2025년 종료되는 폐광지역 개발지원에 관한 특별법 연장 제천삼척간의 고속도로 조기 착공이 이루어질 수 있도록 행정력을 집중하겠습니다지금 우리사회는 대민행정 추진에 평등하고 공정함을 요구하고 있습니다 행정 주도로 이끌어 오던 군정 주요시책과 현안들을 공론화를 통해 결정하고자 그 첫 번째 발걸음으로 청사건립부지 결정을 위한 청사신축공론화위원회 창립총회를 개최하고 활동 중에 있습니다아울러 주민자치회 2개 읍면을 시범적으로 운영하고 주민 제안의 날을 운영하는 등 주민 참여형 행정을 점진적으로 확대해 나가겠습니다강원도에서 ‘2024 강원동계청소년올림픽대회’ 유치를 위해 IOC에게 우선 협상국 자격으로 단독 신청할 경우 유치 전망이 밝다고 합니다제출될 유치계획에 정선에서 설상 경기가 개최될 수 있도록 포함했으며 2018 평창동계올림픽대회의 함성이 정선에서 다시 울려 퍼질 수 있도록 관계 부처와 지속적으로 협의해 나가겠습니다올해 예산은 작년보다 82가 증가한 역대 최고인 4500억원을 편성했습니다군민 여러분의 적극적인 협조와 600여 공직자 여러분의 값진 노력에 대한 대가이기에 다시 한 번 수고하셨다는 말씀을 드립니다‘한 사람이 꾸는 꿈은 꿈으로 끝나지만 여러 사람이 꾸는 꿈은 현실이 된다’는 말처럼 군민 모두가 소통과 공감의 마음으로 노력한다면 우리 정선은 밝고 풍요로운 미래가 다가올 것입니다늘 화합하는 마음을 가져 주시고 사랑하는 마음을 가져 주시고 배려하는 이웃들이 되어 주시면 고맙겠습니다저와 600여 공직자는 군민 여러분의 삶의 변화를 체감할 수 있는 군정을 이끌어 희망찬 아침을 맞이하고 평온한 저녁을 맞이하는 행복한 정선을 만들어 나아가겠습니다새해에도 군민 여러분과 공직자 여러분 가정에 웃음이 가득하고 바라는 모든 소원이 이루어지기를 다시금 소망합니다새해 복 많이 받으십시오 감사합니다\\t\\t\\t\\trimrock@news1kr\\t\\t\\t저작권자 © 뉴스1코리아 무단전재 및 재배포 금지핫뉴스\\r\\t\\t\\t\\t\\t\\t\\t이효리 유재석 앞 임신 말 꺼냈다 DM 세례…노력하겠다\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t곽진영 100억 자산가 1년에 10억 번다…이병헌은 친구\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t하태경 카투사 휴가 규정 軍문서 흔들며 秋 새빨간 거짓말\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t日불교 일련정종 영등포 법당서 집단감염…315명 검사중\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t진중권 맹구 추미애 무개념이 매력…조국과 얼굴두께 경쟁\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t미주 男 시민에 성희롱성 발언 논란…사과\\t\\t\\t\\t\\t\\t 오늘의 핫 포토파란 하늘 아래서 비눗방울에 빠진 동심조영남 대작사건 무죄 판결 후 전시회 개최태풍 지나고 복구 작업의사 국가고시 예정대로 시행응시율 14독감 예방 주사에 눈 질끈소상공인에게 2차 긴급재난지원금 지급 문재인 대통령 질병관리청 승격 감염병 대응체계 획기적 진전'], ['홈  지방   강원 신년사 최승준 정선군수 풍요로운 미래 행복한 정선 만들겠다 \\r\\t\\t\\t\\t\\t정선뉴스1 박하림 기자\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t20200101 0700 송고\\t\\t\\t\\t기사보기네티즌의견Tweet인쇄확대축소최승준 전 정선군수 © News1\\xa0존경하는 군민 여러분희망찬 경자년 새해가 밝았습니다새해 아침의 첫 소망을 담아 군민 여러분의 안정과 번영을 빌면서 소망하는 모든 일들이 이루어지는 한 해가 되길 진심으로 기원 드립니다지난 한 해 희망찬 아침 평온한 저녁 행복한 정선을 만들기 위해 군정을 믿고 보내주신 성원과 진심어린 충고는 우리군이 한 단계 도약하는 데 큰 도움이 되었습니다진심으로 감사드리며 올 한 해도 군민 여러분의 깊은 관심과 성원을 부탁드리겠습니다현대사회는 분열과 빈익빈 부익부 현상으로 불평등은 날로 심해지고 불안은 커지며 미래가 보이지 않는다고 합니다지금과 같은 사회 지금과 같은 삶의 방식이 그대로 유지될 수 있다고 생각하는 것은 어찌보면 환상일지도 모릅니다저는 민선 7기 군수로 취임하면서 공감과 소통을 키워드로 삼아 군민이 주인되는 행복한 정선을 만들겠다고 약속했습니다지난해까지는 공감과 소통으로 기틀을 다졌다면 올 한 해는 군민의 기대에 부응할 수 있는 결실을 맺을 수 있도록 모든 역량을 집결해 군정을 이끄는 데 최선의 노력을 다하겠습니다국민소득 3만불 시대에 맞는 복지정책과 행복하고 살기 좋은 농업․농촌 살맛 나는 지역경제를 위해 군정을 펼쳐 나아가겠습니다먼저 앞서가는 복지정책으로 행복한 정선을 만들겠습니다민선 7기 최우선 과제인 무상 또는 1000원으로 누구나 이용할 수 있는 버스완전공영제를 상반기에 본격적으로 실시하고 희망택시 서비스의 불합리한 부분을 개선하고자 공공형 택시를 도입해 교통복지서비스를 전면 개편하겠습니다모든 군민에게 발생하는 각종 사고와 자연재난으로부터 안전하게 생활할 수 있는 전 군민 안심케어 5대 사업과 정선의 미래를 책임질 인재 양성을 위해 무상교육복지 지원을 확대하고 어르신들의 공공 일자리 창출로 안정된 노후생활 정착과 여성의 경제활동 참여 확대 다문화가정의 안정적 정착 지원을 위한 복지정책도 확대해 나아가겠습니다정선군립병원은 낡은 시설의 구조적인 문제해결을 위해 병동 신축과 의료재단을 설립해 정상적으로 운영하겠으며 농어촌 의료서비스 개선사업의 확대로 의료복지서비스의 질을 높여 모든 계층이 행복한 복지 구현을 실현하겠습니다 둘째 행복하고 살기 좋은 농업․농촌을 만들겠습니다농업인구의 감소와 고령화 경기침체로 인한 농산물 소비 위축과 WTO 농업 분야 개발도상국 지위 포기로 농촌의 현실은 날이 갈수록 어려워지고 있지만 농업은 과거나 현재나 미래에도 한 나라의 근간이자 가장 기초가 되는 산업으로 포기할 수 없습니다주민 소득수준과 생활수준을 높이는 일반농산어촌개발 사업과 기업형 농촌육성사업 농촌체험관광 네트워크 허브조성 6차 산업의 기초가 될 농촌융복합화지구 조성사업을 추진해 침체된 농촌에 새로운 활력을 불어넣겠습니다또한 청년 농업인의 영농정착 지원과 농업대학을 통한 전문농업인을 육성하고 품목별 공동선별시스템 및 가공센터구축 농자재 공동구매로 가격인하 마을공동급식지원 확대를 통해 농산물의 명품화와 가격 경쟁력을 확보해 소득증대에 기여해 나가겠습니다안정적인 농산물 판매를 위해 온오프라인 홍보와 더불어 대형유통망과 직거래 유통을 중심으로 안정적인 농산물 판로를 확보토록 하겠습니다셋째 변화하는 관광트랜드에 맞춰 한 번 더 찾고 싶은 문화관광지로 변모시켜 나가겠습니다최근 관광트랜드는 자연․숲 치유 건강․체력관리 뷰티․미용 명상․정신수양 등의 다양한 테마로 구분되는 웰니스 관광으로 변하고 있습니다힐링음악과 음식을 결합한 가리왕산 뮤직페스티벌 개최로 웰니스 관광상품 개발의 가능성을 보았고 정선아리랑과 향토음식 그리고 기 조성된 관광지와 결합한 웰니스 클러스터를 구축해 변화하는 관광트랜드에 맞춰 우리군 신성장 동력으로 발전시켜 나가겠습니다특히 KTX 경강선을 이용하는 관광객을 유치하기 위해 진부역정선5일장 노선에 2층 관광 셔틀버스를 도입하고 SNS 관광 홍보단과 유튜브 홍보 채널을 통합운영하고 ‘보고싶다 정선아’ 브랜드 마케팅을 다양하게 운영해 특색있는 관광홍보마케팅으로 관광객 유치에 최선을 다하겠습니다폐광지역 경제회생을 위해 추진중인 폐광지역 관광자원화 3단계 사업의 신규사업 발굴과 국비를 확보해 관광산업의 전환점이 될 수 있도록 준비해 나가겠습니다올림픽 레거시로 재탄생한 정선아리랑극 ‘아리아라리’ 의 지속적인 업그레이드와 우리군 대표축제인 정선아리랑제는 전문예술감독 선임과 프로그램 개선을 통해 공연과 축제의 완성도를 높이고 아리샘터에 이어 북평 임계지역에도 생활문화센터를 조성해 누구나 이용할 수 있는 지역문화 기반시설을 확충해 나가겠습니다넷째 군민이 살맛나는 지역경제와 지역개발을 이루어 내겠습니다 먼저 약화되는 골목상권 경쟁력 제고를 위한 정선읍 상권르네상스 사업을 주축으로 9개 읍면 5일장에 추진중인 고객센터 신축사업 골목경제 활성화사업 등은 조기에 완료해 활기찬 시장경제를 이끌어 나가겠습니다고한 야생화마을 추리극장 조성사업 사북읍 빛의 거리 조성사업을 정상적으로 추진해 고한․사북지역을 방문하는 카지노 관광객을 시내로 유도해 지역경제 활성화를 도모하겠습니다또한 북평과 사북지역에 230세대의 아파트 신축 협의 농촌중심지 활성화사업 LPG 배관망 구축 및 도시가스설치 지원사업 추진으로 사람들의 온정이 넘치는 도시와 마을로 재탄생 시켜 정주여건을 개선토록 하겠습니다금년 한 해는 감소하는 인구정책에 대해 획기적인 정책 변화를 시도하겠습니다 인구정책 비전을 ‘모든 세대가 살기 좋은 정선 실현’으로 정하고 일자리 창출 복지서비스 향상 인구변화대응 등의 정책목표로 인구 증가에서 인구유지 정책으로 전환해 인구 감소의 전환점이 되는 정책을 추진하겠습니다우리군의 주요 현안사업인 정선관광의 랜드마크가 될 가칭 아라리교 가설을 위한 재원확보와 2025년 종료되는 폐광지역 개발지원에 관한 특별법 연장 제천삼척간의 고속도로 조기 착공이 이루어질 수 있도록 행정력을 집중하겠습니다지금 우리사회는 대민행정 추진에 평등하고 공정함을 요구하고 있습니다 행정 주도로 이끌어 오던 군정 주요시책과 현안들을 공론화를 통해 결정하고자 그 첫 번째 발걸음으로 청사건립부지 결정을 위한 청사신축공론화위원회 창립총회를 개최하고 활동 중에 있습니다아울러 주민자치회 2개 읍면을 시범적으로 운영하고 주민 제안의 날을 운영하는 등 주민 참여형 행정을 점진적으로 확대해 나가겠습니다강원도에서 ‘2024 강원동계청소년올림픽대회’ 유치를 위해 IOC에게 우선 협상국 자격으로 단독 신청할 경우 유치 전망이 밝다고 합니다제출될 유치계획에 정선에서 설상 경기가 개최될 수 있도록 포함했으며 2018 평창동계올림픽대회의 함성이 정선에서 다시 울려 퍼질 수 있도록 관계 부처와 지속적으로 협의해 나가겠습니다올해 예산은 작년보다 82가 증가한 역대 최고인 4500억원을 편성했습니다군민 여러분의 적극적인 협조와 600여 공직자 여러분의 값진 노력에 대한 대가이기에 다시 한 번 수고하셨다는 말씀을 드립니다‘한 사람이 꾸는 꿈은 꿈으로 끝나지만 여러 사람이 꾸는 꿈은 현실이 된다’는 말처럼 군민 모두가 소통과 공감의 마음으로 노력한다면 우리 정선은 밝고 풍요로운 미래가 다가올 것입니다늘 화합하는 마음을 가져 주시고 사랑하는 마음을 가져 주시고 배려하는 이웃들이 되어 주시면 고맙겠습니다저와 600여 공직자는 군민 여러분의 삶의 변화를 체감할 수 있는 군정을 이끌어 희망찬 아침을 맞이하고 평온한 저녁을 맞이하는 행복한 정선을 만들어 나아가겠습니다새해에도 군민 여러분과 공직자 여러분 가정에 웃음이 가득하고 바라는 모든 소원이 이루어지기를 다시금 소망합니다새해 복 많이 받으십시오 감사합니다\\t\\t\\t\\trimrock@news1kr\\t\\t\\t저작권자 © 뉴스1코리아 무단전재 및 재배포 금지핫뉴스\\r\\t\\t\\t\\t\\t\\t\\t이효리 유재석 앞 임신 말 꺼냈다 DM 세례…노력하겠다\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t곽진영 100억 자산가 1년에 10억 번다…이병헌은 친구\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t하태경 카투사 휴가 규정 軍문서 흔들며 秋 새빨간 거짓말\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t日불교 일련정종 영등포 법당서 집단감염…315명 검사중\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t진중권 맹구 추미애 무개념이 매력…조국과 얼굴두께 경쟁\\t\\t\\t\\t\\t\\t\\r\\t\\t\\t\\t\\t\\t\\t미주 男 시민에 성희롱성 발언 논란…사과'], ['20200101 0732글자크기글자크기조절가나다라마가나다라마가나다라마가나다라마가나다라마댓글제 15회 머니투데이 경제신춘문예곽흥렬수필 습관은 낯설던 것도 익숙하게 만드는 힘을 지녔는가보다\\r 이십여 년쯤 전의 일이다 ‘신용카드’라는 말이 처음 사람들의 입에 오르내리기 시작했을 무렵 카드를 만져보기는커녕 구경조차 하기가 힘이 들었었다 카드란 것이 마치 무슨 특권을 부여받은 특정계층의 사람들이나 사용하는 물건인 줄 알던 때였다 이를테면 지금으로부터 불과 이삼 십여 년 전 자가용이 보편화 되지 않았을 시절 도로 위를 미끄러지듯 질주하는 검은색 세단을 보면 우리 같은 샐러리맨들과는 상관없는 별세상의 사람들만 소유하는 물건인 양 생각되던 것과 비슷한 경우라고나 할까 \\r  어쨌든 자가용은 보통사람들로서는 도저히 가 닿을 수 없는 엄청난 부러움의 대상이었다 나는 언제 저런 걸 한 번 가져 보나 그것은 이루어질 수 없는 꿈이요 막연한 동경의 상징물일 뿐이었다 아니 꿈을 꾼다는 것 자체가 허황한 망상 같았다 하지만 그 꿈만 같았던 자동차를 이제 용기만 내면 가질 수 있게 된 것처럼 누구든 마음만 먹으면 얼마든지 자유롭게 신용카드의 주인이 될 수 있는 세상으로 바뀌었다 어떻게 생각하면 신용카드가 사람들의 평등지수를 끌어올리는 데 톡톡히 한몫을 한 셈이다 \\r  요즘 세상에 신용카드 한두 장 갖지 않은 사람이 있을까 내남없이 지갑 속 깊숙한 곳에 예쁘게 디자인이 된 신용카드가 신줏단지처럼 모셔져 있다 물론 카드회사들의 과열경쟁으로 말미암아 애초 발급받아서는 아니 되는 미성년자들이나 신용불량자들까지 카드를 소지하여 말썽을 일으키는 사례가 없지는 않지만 이것이 카드가 통용됨으로 해서 얻어지는 순기능에 비하면 그다지 큰 문제일 수는 없다는 생각이다 \\r  세상만사 그 무엇이든 빛과 그림자는 항상 공존하게 마련이어서 카드 사용으로 인해 발생하는 얼마간의 문제점을 집중 조명하여 그 심각성 운운하는 것은 빈대 잡으려다 초가삼간 태우는 우를 범하는 격이 된다 인간사에는 완벽하게 긍정적인 면만 가진 것도 없으며 그렇다고 완벽하게 부정적인 면만 지닌 것도 없지 않은가 아무리 좋은 선약일지라도 거기에는 필시 부작용이 있으며 설사 비상砒霜 같은 극약일지라도 극미량으로 적절히 사용하기만 한다면 고질병의 치료에 특효약이 되기도 한다\\r  신용카드도 마찬가지가 아닐까 싶다 일상생활에 더없이 편리한 이 신용카드도 제 분수를 모르는 무절제한 사용으로 인해 작게는 한 개인 또는 가정의 파탄을 불러오고 크게는 국가 경제를 좀 먹히는 경우가 비일비재하다 그에 반해 절도 있는 알뜰한 사용은 생활의 질을 향상시키고 갖가지 편리함과 이득을 선사해 준다 지갑 속에 항시 두툼하게 현금을 보관하고 다녀야 하는 번거로운 상황에 비해 간편하기가 그만이고 예기치 않게 급전이 필요한 경우가 생겼을 때 지갑의 두께가 얇아도 낭패감을 느끼지 않아 보디가드를 둔 것처럼 든든하다 거기다가 요즘처럼 온갖 범죄가 득시글거리는 어수선한 세상에서 현금을 소매치기 당할 걱정으로부터 자유로울 수 있음은 또 얼마나 마음 푸근한 보너스인가 \\r  소매치기 이야기만 나오면 나는 어김없이 시골집에 홀로 계신 아버지 생각이 떠오른다 아버지는 소싯적부터 줄곧 시골서 살아오신 까닭에 도시의 물정에 어두웠다 그래서 그런지 어디 출타를 해도 안주머니 간수에 그다지 신경을 쓰시지 않는 편이다 덕분에 이따금 친지의 예식이 있거나 아들집에 방문하는 따위의 일로 도시에 나와서는 붐비는 버스 간에서 양복 안주머니를 털리는 일이 여러 차례였다 \\r  그 가운데서도 가장 가슴 아픈 일은 그러니까 내가 열두어 살 초등학생 시절에 벌어졌다 지금으로부터 삼십 년도 더 된 이야기다 그때 아버지는 황소 몇 마리를 사 키우기 위해 대구 사는 막내고모 댁에 돈을 빌리러 가신 적이 있었던 모양이다 하도 오래 전의 일이라 분명치는 않지만 어머니의 말에 의하면 그때 잃어버린 돈이 오만 원이었던 것으로 기억된다 당시 오만 원이란 요즘의 금새로 따지면 꽤나 큰돈이었다 아마도 오백 만 원 가량은 넉넉히 됨직하다 \\r  아버지는 필요한 돈을 구해서 서부정류장행 시내버스를 타셨고 그 안에서 그만 소매치기를 당하고 만 것이다 그런 사실을 당신은 집에 도착할 때까지도 까마득히 모르고 계셨던 것 같다 어머니가 겉옷을 받아 걸면서 양복 안주머니에 난 면도칼 자국을 확인하고 거의 실신할 지경으로 놀라 하던 모습이 지금도 눈앞에 생생하다 물론 떠나기 전에 어머니는 도시 나가거든 어떻든지 주머니 조심해서 택시를 타고 다니라며 신신당부를 잊지 않았다고 했다 아버지는 어머니의 말을 곧이듣지 않았다 당시로서는 쌀에 뉘처럼 귀하던 택시 삯이 당신 생각으로는 심히 부담스러웠던 게 틀림없다 쪼들린 집안 형편을 먼저 생각하셨을 아버지였다 그래서 당신 자신만 믿고 ‘뭐 어떻기야 하려고’ 이러면서 태연스레 버스로 귀가하다 아니나 다를까 그만 주머니를 털리고 만 것이었다\\r  아버지는 그 충격으로 한동안 실어증에 걸린 사람처럼 말문을 닫아버렸다 식음을 전폐하고 구들목에 드러누워 누구와도 접촉을 끊었다 어머니는 잃어버린 돈은 고사하고 저러다가 사람까지 버리겠다며 아버지를 붙들고 통사정을 했다 그 돈 잃어버린 사람은 발 뻗고 자도 훔쳐간 놈은 발 뻗고 못 자니 그만 잊어 버립시다\\r  아버지는 어머니의 간곡한 설득에 근 열흘 만에야 자리를 털고 일어났다 그리고는 조금씩 아주 조금씩 마음을 추스르며 잃었던 의욕을 되찾아 갔다 아버지가 다시 예전의 삶으로 돌아오는 데는 하 많은 세월의 약이 필요했다 이제는 옛이야기 삼아 담담히 꺼내 놓으실 수 있게 되긴 했지만 생각해 보면 지금도 참 가슴 아픈 일이 아닐 수 없다 만약 그때 신용카드란 것이 있었더라면 아버지는 분명 그날의 참담한 낭패는 당하지 않으셨을 게다 빌린 돈을 가까운 은행에 입금시켜 놓고 집으로 돌아와 얼마든지 안전하게 찾아 쓸 수 있었을 일이 아닌가 \\r  한 집에 한 집 꼴로 전화가 널리 보급된 십여 년 전 실로 전화 없이는 하루도 살 수 없을 것만 같이 우리는 생활의 편리를 누렸다 몇 날 며칠씩 걸리는 편지 대신 단 몇 분 만에 이런저런 소식을 전할 수 있으니 여간 신통방통한 물건이 아니었다 \\r  그 무렵 하나둘 휴대전화란 것이 눈에 띄기 시작했다 사람들은 지난날의 자가용처럼 강한 호기심은 두면서도 선뜻 가질 엄두를 내지 못했다 당시 금액으로 몇 백만 원 하던 휴대전화가 서민들에게는 말 그대로 그림의 떡이었다 그러다 세월이 흐르고 조금씩 보급이 늘어나면서 단가가 낮아지자 너도나도 휴대전화를 가지는 것이 유행처럼 번져갔다 이렇게 된 것이 불과 몇 십 년 안짝의 일이다 \\r  일전에 어느 일간지에서 이 땅의 휴대전화 보급률이 벌써 오천만 대를 넘어섰다는 통계자료를 얼핏 본 적이 있다 경제활동을 하는 사람들은 말할 것도 없고 심지어 노인 학생 주부들까지 휴대전화의 편리함을 만끽하고 있다고 했다 일반전화가 처음 보편화되었을 때 전화 없이는 살지 못할 것 같았는데 이제 휴대전화 없이는 하루도 살기 힘든 세상이 되었다 말하자면 생활필수품으로 당당히 자리매김한 셈이다\\r  신용카드 역시 거기에 조금도 뒤지지 않는다 만일 어떤 힘센 권력자가 나서서 지금 당장 우리가 소지한 신용카드를 하나도 남김없이 몽땅 회수해 버리겠다고 을러댄다면 사람들은 우리더러 원시시대로 돌아가라는 말이냐고 벌떼처럼 들고 일어설 것이 뻔하다 신용카드는 그만큼 우리들 생활의 필수소지품으로 자리 잡았다 아니 현대사회에서 없어서는 안 될 분신 같은 존재가 되었다고 하는 편이 오히려 옳을 것 같다 신용사회야말로 우리가 꿈꾸는 이상적인 세상이 아닌가 이러한 세상의 건설에 신용카드는 그 첨병 역할을 톡톡히 하고 있다\\r  물론 세상에는 신용카드로 해서 패가망신한 사람들의 경우가 심심찮게 인구에 회자된다 능력도 되지 않으면서 무조건 쓰고 보자는 식의 막무가내식 소비는 활발히 꽃을 피우고 있는 신용사회의 어두운 그림자다 그러나 앞서도 잠깐 짚고 넘어간 이야기이긴 하지만 세상만사 빛이 있으면 반드시 그 그림자도 있게 마련인 법 신용카드라고 해서 빛만 있고 그림자가 없을 수는 없지 않은가 이럴 경우 설사 그 그림자를 완전히 없애지는 못한다 할지라도 그 농도를 보다 엷게 하는 것은 그리 어려운 일이 아닐 게다 방법은 의외로 간단하다 그것은 밝은 빛을 더욱 밝히려는 우리의 각오 하나에 달렸다 각자 지갑에서 뽑아들기 전에 한 번 더 생각하고 알뜰하게 관리만 한다면 신용카드만큼 간편하고 쓰임새 있는 물건도 다시없을 듯하다 자동차며 휴대전화가 비록 아무리 편리하다 해도 때로는 불편함도 그에 못지않다 자동차는 어쩌다 고장이 나거나 만에 하나 불의의 사고라도 일어나는 날이면 여간 성가신 게 아니고 휴대전화는 시도 때도 없이 걸려오는 불필요한 광고성 전화에 오히려 신경을 곤두세우게 되는 일이 얼마나 많은가 거기에 비해 신용카드는 자기만 살뜰하고 계획적이면 이런저런 성가심에서 자유로울 수 있으니 자동차며 휴대전화 따위에 비길 바가 아니다\\r  얼마 전 나는 가까운 은행에 아버지를 모시고 가서 당신 명의의 신용카드 한 장을 만들었다 팔십 줄을 넘어선 노인이기에 여러 장의 카드는 번거로울 것 같아 딱 한 장만 마련해 드렸다 아버지는 병원에 가실 때나 뭘 사 드시고 싶거나 하는 일로 지출이 필요할 때 요긴하게 신용카드를 사용하신다 그러면서 이 편리한 걸 왜 진작 쓸 줄 몰랐을꼬라며 어느새 신용카드 예찬론자가 되셨다 \\r  내 지갑 속에도 석 장의 신용카드가 신줏단지처럼 모셔져 있다 많지도 적지도 않은 숫자다 오천 원 이상을 결제해야 할 때면 언제나 신용카드를 내민다 나 개인은 물론이고 국가 경제를 투명하게 한다는 나름의 자부심도 은연중에 작용하고 있으니 누이 좋고 매부 좋은 일이 아니겠는가 ‘알뜰하게 쓰자’ 이 한마디를 늘 마음속 깊이 돋을새김으로 새겨 넣고서                                                                저작권자 © ‘돈이 보이는 리얼타임 뉴스’ 머니투데이 무단전재 및 재배포 금지                                공감                                            0비공감                                            0머니투데이 댓글 작성을 위해 JavaScript를 활성화해주세요머니투데이 주요뉴스테슬라만 있을쏘냐…원정개미 中항서제약美해즈브로 정복의사국시 미응시로 내년 인턴 부족 정부 대체 불가능한 전문업무 아니다\\t\\t\\t\\t\\t\\t정부가 의대생의 국가실기시험 대규모 미응시로 내년도 인턴 수급에 어려움을 겪을 것이란 전망에 대해 대체 불가능할 정도의 고도의 전문적인 업무는 아니다라고 평가했다손영래 중앙사고수습본부 전력기획반장 겸 보건복지부 대변은은 8일 중앙재난안전본부 정례브리핑에서 수련병원들과 함께 인턴수급 부족 문제에 \\t\\t\\t\\t\\t軍 카투사 휴가 육군 규정 따른다…秋측 거짓해명 논란의협 정부민주당 뒤통수 계속치면 의정합의 철회PB도 모르는 정보 들고오는 개미들해외펀드 빼서 주식 직구사전청약 효과 3040 패닉바잉 잠잠해지겠만 집값은…文대통령 초대 질병관리청장에 코로나 영웅 정은경 내정한강매점 폐쇄해도 배달하면 그만서울시 자제 호소주호영 이낙연 공수처 공세에 법대로 하자국민의힘 당명 알고보니 日극우단체 구호코로나 확진 교수 수업 중 사망…마지막 말은'], [''], ['']] 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxPages 11\n",
      "https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%ED%98%84%EB%8C%80%20%EC%82%AC%ED%9A%8C%20%EB%AC%B8%EC%A0%9C&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&ds=2020.01.01&de=2020.01.01&docid=&nso=so%3Ar%2Cp%3Afrom20200101to20200101%2Ca%3Aall&mynews=0&refresh_start=0&related=0\n",
      "10\n",
      "==================== 1 ====================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 크롤링 메인 함수 - 1일 기준 \n",
    "y = Year m = Month, d = Day, txt = Keyword, pathName = 파일 위치, fileName = output 될 메인파일이름 \n",
    "output 파일은 이런 형식으로 {name}_{y}-{m}-{d}' \n",
    "\"\"\"\n",
    "page    = 1\n",
    "dic     = {}\n",
    "dic_sub = {}\n",
    "mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "\n",
    "m = StrDate(m) # Date Type\n",
    "d = StrDate(d)\n",
    "\n",
    "Running = True \n",
    "while Running:\n",
    "\n",
    "    targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "    Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "    subUrl         = SubContents( targetUrl )\n",
    "    SubCont     = Subtxt( subUrl ) \n",
    "    print(SubCont, len(SubCont))\n",
    "\n",
    "    CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "    print(targetUrl) \n",
    "    try:\n",
    "        Titles, Posts = BasicContents( targetUrl )\n",
    "    except:\n",
    "        Titles = 'NaN'\n",
    "        Posts  = 'NaN'\n",
    "\n",
    "    date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "\n",
    "    dic['Title'] = Titles\n",
    "    dic['Post']  = Posts\n",
    "    dic['Date']  = date\n",
    "#     dic['SubContent'] = box\n",
    "    print(len(dic['Title']))\n",
    "    \n",
    "    df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "\n",
    "    fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "    SaveFile(df, fullDstName, 'a', False,  'UTF-8') # df, fullDstName,  Mode, index, encoding\n",
    "    print( '='*20, f'{page}','='*20 )\n",
    "    page += 10 \n",
    "\n",
    "    #  종료 옵션 \n",
    "    if page == 4001 :  # Crawling max page 4000!\n",
    "        Running = False\n",
    "    elif TitPages == 0 :\n",
    "        Running = False\n",
    "    elif page == (TitPages*10)+1:\n",
    "        Running = False\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "# re.sub(punc,'',p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Code': ['content', 'article', 'CmAdContent']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_result['Code']= dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # path =  pathName +  dirPath[0] + \"/\" \n",
    "# # pathName = 'C:/data/'  # 사용자 임의\n",
    "# # 변수 : 사용자 설정 \n",
    "# fileName     = 'test' \n",
    "# txt          = '사회문제' \n",
    "# start_month  = 1\n",
    "# end_month    = 1\n",
    "# year         = 2020\n",
    "\n",
    "# # mkDir( pathName, fileName )   #  폴더 생성 만약 있으면 pass\n",
    "\n",
    "# # 기간 + 크롤링(전체 기간을 돌리는 경우 break 제거해야합니다.)\n",
    "# thirtyOne = [1,3,5,7,8,10,12] \n",
    "# for mth in range(start_month, end_month+1):\n",
    "#     if mth == 2 : # 2월 \n",
    "#         for dt in range(1,30):\n",
    "#             Main( year, mth, dt, txt, pathName, fileName ) # 크롤링 코드 1일 \n",
    "#             break\n",
    "#     elif mth not in thirtyOne : \n",
    "#         for dt in range(1,31):\n",
    "#             Main( year, mth, dt, txt, pathName, fileName )\n",
    "#             break\n",
    "#     else:\n",
    "#         for dt in range(1,32):\n",
    "#             Main( year, mth, dt, txt, pathName, fileName )\n",
    "#             break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = SubContents(targetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.donga.com/news/article/all/20200902/102750395/1\n",
      "http://www.fnnews.com/news/202009011747032336\n",
      "http://www.jbnews.com/news/articleView.html?idxno=1304965\n",
      "http://www.inews24.com/view/1295321\n",
      "https://www.news1.kr/articles/?4045882\n",
      "http://star.mk.co.kr/new/view.php?mc=ST&year=2020&no=905412\n",
      "http://www.breaknews.com/752724\n",
      "http://www.newswatch.kr/news/articleView.html?idxno=50774\n",
      "https://platum.kr/archives/147802\n",
      "http://www.kukinews.com/newsView/kuk202008310170\n"
     ]
    }
   ],
   "source": [
    "for i in SubContents(targetUrl):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.donga.com/news/article/all/20200902/102750395/1'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testUrl = 'http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# page    = 1\n",
    "# dic     = {}\n",
    "# dic_sub = {}\n",
    "# mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "\n",
    "# m = StrDate(m) # Date Type\n",
    "# d = StrDate(d)\n",
    "\n",
    "# Running = True \n",
    "# while Running:\n",
    "\n",
    "#     targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "#     Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "#     subUrl         = SubContents( targetUrl )\n",
    "#     SubCont        = Subtxt( subUrl ) \n",
    "#     print(SubCont, len(SubCont))\n",
    "\n",
    "#     CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "#     print(targetUrl) \n",
    "#     try:\n",
    "#         Titles, Posts = BasicContents( targetUrl )\n",
    "#     except:\n",
    "#         Titles = 'NaN'\n",
    "#         Posts  = 'NaN'\n",
    "\n",
    "#     date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "\n",
    "#     dic['Title'] = Titles\n",
    "#     dic['Post']  = Posts\n",
    "#     dic['Date']  = date\n",
    "\n",
    "#     print(len(dic['Title']))\n",
    "    \n",
    "#     df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "\n",
    "#     fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "#     SaveFile(df, fullDstName, 'a', False,  'UTF-8') # df, fullDstName,  Mode, index, encoding\n",
    "#     print( '='*20, f'{page}','='*20 )\n",
    "#     page += 10 \n",
    "\n",
    "#     #  종료 옵션 \n",
    "#     if page == 4001 :  # Crawling max page 4000!\n",
    "#         Running = False\n",
    "#     elif TitPages == 0 :\n",
    "#         Running = False\n",
    "#     elif page == (TitPages*10)+1:\n",
    "#         Running = False\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubContents( targetUrl ):\n",
    "    \"\"\"\n",
    "    SubContents\n",
    "    #News address  = targetUrl\n",
    "    \"\"\"\n",
    "    soup    = Soup( targetUrl )\n",
    "    urlNew  = [i['href'] for i in soup.select( '.news .type01 li dt a')]\n",
    "    print(urlNew)\n",
    "    \n",
    "    return urlNew   \n",
    "\n",
    "\n",
    "\n",
    "def Subtxt( Url ):\n",
    "    \n",
    "    \"\"\"\n",
    "    로직이 이상해 -> \n",
    "    \"\"\"\n",
    "    box = list()\n",
    "    \n",
    "    for url in Url:\n",
    "        \n",
    "        id_result = {'Code': ['content', 'article', 'CmAdContent', 'articleWrap','article_body_content']}\n",
    "        punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "        soup    = Soup(url) # func\n",
    "\n",
    "        for code in id_result['Code']:\n",
    "            cont    = [re.sub(punc,'',i.text).strip().replace('\\n','') for i in soup.select('#'+code)]\n",
    "            if len(cont) != 0:\n",
    "                print(url)\n",
    "                print([re.search(r'< .*? id=\"(.*?)\">',i.text) for i in soup.select('#'+code)])\n",
    "                box.append(cont)\n",
    "                pass\n",
    "            elif len(cont) == 0 and not code in id_result['Code'] :\n",
    "                print('test', url)\n",
    "                \n",
    "                \n",
    "            elif code in id_result['Code']:\n",
    "                pass \n",
    "            \n",
    "            else : \n",
    "                print([re.search(r'< .*? id=\"(.*?)\">',i.text) for i in soup.select('#'+code)])\n",
    "                print('missUrl', url)\n",
    "\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "d = 1\n",
    "y = 2020\n",
    "\n",
    "pathName = 'C:/TmP/' # 사용자가 원하는 경로\n",
    "fileName     = 'test' \n",
    "txt          = '현대 사회 문제' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exist\n",
      "['http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374', 'http://yna.kr/AKR20200101009951504?did=1195m', 'https://www.artinsight.co.kr/news/view.php?no=45507', 'http://news1.kr/articles/?3806084', 'http://www.hankookilbo.com/news/npath/202001010720336919?did=NA', 'http://news.maxmovie.com/411055', 'http://news.mt.co.kr/mtview.php?no=2019122013344318125', 'http://www.newscj.com/news/articleView.html?idxno=695916', 'http://www.gndomin.com/news/articleView.html?idxno=228517', 'http://www.hankookilbo.com/news/npath/201912301356359103?did=NA']\n",
      "http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374\n",
      "[None]\n",
      "http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403374\n",
      "[None]\n",
      "http://yna.kr/AKR20200101009951504?did=1195m\n",
      "[None]\n",
      "http://news1.kr/articles/?3806084\n",
      "[None]\n",
      "http://news1.kr/articles/?3806084\n",
      "[None]\n",
      "http://news.mt.co.kr/mtview.php?no=2019122013344318125\n",
      "[None]\n",
      "http://www.newscj.com/news/articleView.html?idxno=695916\n",
      "[None]\n",
      "http://www.gndomin.com/news/articleView.html?idxno=228517\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "page    = 1\n",
    "dic     = {}\n",
    "dic_sub = {}\n",
    "mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "\n",
    "m = StrDate(m) # Date Type\n",
    "d = StrDate(d)\n",
    "\n",
    "\n",
    "targetUrl      = PageUrl( txt, y, m, d, page ) \n",
    "subUrl         = SubContents( targetUrl )\n",
    "SubCont        = Subtxt( subUrl ) \n",
    "# print(SubCont, len(SubCont))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 절에서 다운로드한 파일을 열고 html이라는 변수에 저장\n",
    "with open('dp.html', encoding='utf-8') as f:\n",
    "    html = f.read()\n",
    "    \n",
    "# re.findall() 메서드를 통해 도서 하나에 해당하는 HTML을 추출\n",
    "for partial_html in re.findall(r'<td class=\"left\"><a.*?</td>', html, re.DOTALL):\n",
    "    # 도서의 URL을 추출\n",
    "    url = re.search(r'<a href=\"(.*?)\">', partial_html).group(1)\n",
    "    url = 'http://www.hanbit.co.kr' + url\n",
    "    # 태그를 제거해서 도서의 제목을 추출\n",
    "    title = re.sub(r'<.*?>', '', partial_html)\n",
    "    title = unescape(title)\n",
    "    print('url:', url)\n",
    "    print('title:', title)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-5da19df669c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print(soup)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpartial_html\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'<td class=\"left\"><a.*?</td>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# 도서의 URL을 추출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0murlt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'< .*? id=\"(.*?)\">'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import re\n",
    "id_result = {'Code': ['content', 'article', 'CmAdContent', 'articleWrap','article_body_content']}\n",
    "punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "soup    = Soup(testUrl) # func\n",
    "\n",
    "# print(soup)\n",
    "\n",
    "for partial_html in re.findall(r'<td class=\"left\"><a.*?</td>', soup, re.DOTALL):\n",
    "    # 도서의 URL을 추출\n",
    "    urlt = re.search(r'< .*? id=\"(.*?)\">', soup)\n",
    "    print(urlt)\n",
    "# print(re.sub(punc,'',i.text).strip().replace('\\n','') for i in soup.select('#'+code))\n",
    "# for code in id_result['Code']:\n",
    "#     cont    = [re.sub(punc,'',i.text).strip().replace('\\n','') for i in soup.select('#'+code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
