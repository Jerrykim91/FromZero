{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MakeNouns( pathName, fileName, Contents ):\n",
    "#     \"\"\"\n",
    "#     만약 Kkma가 설치 되어 있다면 상관없음 \n",
    "#     없으면 설치 권장 \n",
    "#     \"\"\"\n",
    "#     from konlpy.tag import Kkma\n",
    "#     kkma = Kkma()\n",
    "#     path = pathName + fileName\n",
    "#     df_origin  = pd.read_csv( path + '.csv', index_col=False)\n",
    "#     df = df_origin\n",
    "    \n",
    "#     df['Keyword'] = None  # 초기값 세팅 \n",
    "    \n",
    "#     for idx, sen in tqdm(enumerate(Contents)):\n",
    "#         chge   = re.compile('[가-힣. ]+').findall(sen) # 정규식 1차 처리\n",
    "#         nouns  = kkma.nouns( ' '.join(chge) ) # 띄워쓰기 후 명사 추출  \n",
    "#         df['Keyword'][idx] = nouns\n",
    "        \n",
    "#     fullDstName =  path + '_Keyword.csv'\n",
    "#     SaveFile(df, fullDstName,'w', False, 'utf-8-sig' )    \n",
    "    \n",
    "#     return print('Finish !')\n",
    "\n",
    "\n",
    "# def TotalStr(Bunch):\n",
    "#     \"\"\"\n",
    "#     # 리스트안의 중복된 값의 개수\n",
    "#     string 중복값 생성 \n",
    "#     \"\"\"\n",
    "#     import operator\n",
    "\n",
    "#     oneWords = dict()\n",
    "#     for lst in Bunch:\n",
    "#         try: oneWords[lst] += 1\n",
    "#         except: oneWords[lst]=1\n",
    "\n",
    "#     oneWord = sorted(oneWords.items(),reverse=True, key=operator.itemgetter(1))\n",
    "    \n",
    "#     return oneWord\n",
    "\n",
    "\n",
    "# # 자동화 함수 - 구글드라이버를 통해 진행\n",
    "# def GetConfirmToken(response):\n",
    "#     \"\"\"\n",
    "#     # 토큰 받기 \n",
    "#     \"\"\"\n",
    "#     for key, val in response.cookies.items():\n",
    "#         if key.startswith(\"download_warning\"): #  특정 문자로 시작하는지의 여부\n",
    "#             return val\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def SaveResContent(response, destination ):\n",
    "#     \"\"\"\n",
    "#     한 번에 하나씩 데이터를 읽어 Chunk라는 덩어리를 만든 후  \n",
    "#     Chunk 단위로 트랜잭션 -> chunkSize별로 묶어서 처리\n",
    "#     \"\"\"\n",
    "#     chunkSize = 32768\n",
    "#     with open(destination, \"wb\") as f:\n",
    "#         for chunk in response.iter_content(chunkSize):\n",
    "#             if chunk : \n",
    "#                 f.write(chunk)   \n",
    "\n",
    "# def DownloadFunc(id_, destination):\n",
    "#     \"\"\"\n",
    "#     # 구글 드라이버를 통해 데이터 자동 다운로드 \n",
    "#     # id_ : 아이디 -> 제공 \n",
    "#     # destination : 경로 = pathName\n",
    "#     \"\"\"\n",
    "#     baseUrl = \"https://docs.google.com/uc?export=download\"\n",
    "#     session = requests.Session()\n",
    "#     res   = session.get(baseUrl, params = { 'id' : id_ }, stream = True )\n",
    "#     token = GetConfirmToken(res)\n",
    "#     if token:\n",
    "#         params = { 'id' : id_, 'confirm' : token }\n",
    "#         res    = session.get( baseUrl, params = params, stream = True )\n",
    "#         print(f'성공 : {res}')\n",
    "    \n",
    "#     print('다운로드 시작')    \n",
    "#     baseName = res.headers['Content-Disposition'].split(';')[1].split('filename=')[1].replace('\\\"', '')\n",
    "#     fullFileName = path.join( destination, baseName )\n",
    "#     SaveResContent( res, fullFileName )\n",
    "#     print('진행 중 ')\n",
    "#     return fullFileName\n",
    "\n",
    "\n",
    "\n",
    "# def DownloadFromGoogleDrive(fileId, destination):\n",
    "#     \"\"\"\n",
    "#     # 구글 데이터 다운로드   \n",
    "#     fileId   : id 코드 \n",
    "#     pathName : 다운로드 경로 \n",
    "#     \"\"\"\n",
    "#     cnt = 0 \n",
    "#     filenameList = list()\n",
    "#     os.makedirs(destination, exist_ok = True)\n",
    "#     try:\n",
    "#         if len(fileId) == 33 and type(fileId) == str :\n",
    "#             download_func = partial( DownloadFunc, destination = pathName )\n",
    "#             print('다운로드 진행중!')\n",
    "#             fileName = DownloadFunc( id_ = fileId, destination = pathName )\n",
    "#             print(f'{fileName} 완료!')\n",
    "#             filenameList.append(fileName)   \n",
    "\n",
    "#         elif type(fileId) == list :\n",
    "#             for key in tqdm(fileId):\n",
    "#                 cnt += 1 \n",
    "#                 download_func = partial( DownloadFunc, destination = pathName )\n",
    "#                 print('다운로드 진행중!')\n",
    "#                 fileName = DownloadFunc( id_ = key, destination = pathName )\n",
    "#                 print(f'{cnt}번째 {fileName} 완료!')\n",
    "#                 filenameList.append(fileName)   \n",
    "#                 print('='*60)\n",
    "#         else:\n",
    "#             print(' 33자리 Id 코드가 필요합니다. 확인해 주세요!')    \n",
    "                \n",
    "#     except Exception as err:\n",
    "#         print(f'{err} : 에러 발생')\n",
    "        \n",
    "#     return filenameList\n",
    "\n",
    "\n",
    "# def Unzip(filenameList):\n",
    "#     \"\"\"\n",
    "#     # 압축 해제\n",
    "#     \"\"\"\n",
    "#     zipFileNameList = [ pathName for pathName in filenameList if pathName.endswith('.zip')]\n",
    "#     for file in tqdm(zipFileNameList):\n",
    "#         print(f'{file} 진행중!')\n",
    "#         with zipfile.ZipFile(file) as targetZip:\n",
    "#             destPath = path.splitext(file)[0]\n",
    "#             os.makedirs(destPath, exist_ok=True)\n",
    "#             targetZip.extractall(destPath)\n",
    "#             print(f'{destPath} 완료!')\n",
    "#         print(f'.zip 파일삭제 {os.remove(file)}')      \n",
    "\n",
    "\n",
    "# def SaveFile( df, fullDstName,  Mode, index, encoding ):\n",
    "#     \"\"\"\n",
    "#     df = 데이터 프레임\n",
    "#     Mode = 만약 덮어쓰기가 있다면 a , 그냥 생성 w\n",
    "#     fullDstName =  path + 파일 확장자(확장자 주의 요말)\n",
    "#     index = False\n",
    "#     encoding = 인코딩 \n",
    "#     header -> 덮어쓰기에만 적용\n",
    "#     # 2018, 2019, 2020\n",
    "#     \"\"\"\n",
    "#     if fullDstName.split('.')[1] == 'csv' :\n",
    "#         if Mode == 'a' : \n",
    "#             # 파일 여부 확인 후 생성 \n",
    "#             if not os.path.exists( fullDstName ):\n",
    "#                 df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "#             else: \n",
    "#                 df.to_csv( fullDstName , index = index, mode = 'a', encoding = encoding, header = False ) \n",
    "#         else:\n",
    "#             df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "\n",
    "        \n",
    "#     elif fullDstName.split('.')[1] == 'xlsx' :\n",
    "#         if Mode == 'a' : \n",
    "#             # 파일 여부 확인 후 생성 \n",
    "#             if not os.path.exists( fullDstName ):\n",
    "#                 df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "#             else: \n",
    "#                 df.to_xlsx( fullDstName , index = index, mode = 'a', encoding = encoding, header = False )\n",
    "#         else:\n",
    "#             df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "#     else:\n",
    "#         print('Please check your file path! Only, xlsx and csv can use')\n",
    "\n",
    "\n",
    "\n",
    "# def Main( y, m, d, txt, pathName, fileName):\n",
    "#     \"\"\"\n",
    "#     # 크롤링 메인 함수 - 1일 기준 \n",
    "#     y = Year m = Month, d = Day, txt = Keyword, pathName = 파일 위치, fileName = output 될 메인파일이름 \n",
    "#     output 파일은 이런 형식으로 {name}_{y}-{m}-{d}' \n",
    "#     \"\"\"\n",
    "#     page    = 1\n",
    "#     dic     = {}\n",
    "    \n",
    "#     mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "    \n",
    "#     m = StrDate(m) # Date Type\n",
    "#     d = StrDate(d)\n",
    "        \n",
    "#     Running = True \n",
    "#     while Running:\n",
    "        \n",
    "#         targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "#         Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "#         CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "#         print(targetUrl) \n",
    "#         try:\n",
    "#             Titles, Posts = BasicContents( targetUrl )\n",
    "#         except:\n",
    "#             Titles = 'NaN'\n",
    "#             Posts  = 'NaN'\n",
    "\n",
    "#         date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "        \n",
    "#         dic['Title'] = Titles\n",
    "#         dic['Post']  = Posts\n",
    "#         dic['Date']  = date\n",
    "        \n",
    "#         df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "        \n",
    "#         fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "#         SaveFile(df, fullDstName, 'a', False,  'utf-8-sig') # df, fullDstName,  Mode, index, encoding\n",
    "#         print( '='*20, f'{page}','='*20 )\n",
    "#         page += 10 l\n",
    "        \n",
    "#         #  종료 옵션 \n",
    "#         if page == 4001 :  # Crawling max page 4000!\n",
    "#             Running = False\n",
    "#         elif TitPages == 0 :\n",
    "#             Running = False\n",
    "#         elif page == (TitPages*10)+1:\n",
    "#             Running = False\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, time, re\n",
    "import pandas as pd\n",
    "\n",
    "# 크롤링\n",
    "import requests\n",
    "import urllib.request\n",
    "import lxml.html\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFile( df, fullDstName,  Mode, index, encoding ):\n",
    "    \"\"\"\n",
    "    df = 데이터 프레임\n",
    "    Mode = 만약 덮어쓰기가 있다면 a , 그냥 생성 w\n",
    "    fullDstName =  path + 파일 확장자(확장자 주의 요말)\n",
    "    index = False\n",
    "    encoding = 인코딩 \n",
    "    header -> 덮어쓰기에만 적용\n",
    "    # 2018, 2019, 2020\n",
    "    \"\"\"\n",
    "    if fullDstName.split('.')[1] == 'csv' :\n",
    "        if Mode == 'a' : \n",
    "            # 파일 여부 확인 후 생성 \n",
    "            if not os.path.exists( fullDstName ):\n",
    "                df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "            else: \n",
    "                df.to_csv( fullDstName , index = index, mode = 'a', encoding = encoding, header = False ) \n",
    "        else:\n",
    "            df.to_csv( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "\n",
    "        \n",
    "    elif fullDstName.split('.')[1] == 'xlsx' :\n",
    "        if Mode == 'a' : \n",
    "            # 파일 여부 확인 후 생성 \n",
    "            if not os.path.exists( fullDstName ):\n",
    "                df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "            else: \n",
    "                df.to_xlsx( fullDstName , index = index, mode = 'a', encoding = encoding, header = False )\n",
    "        else:\n",
    "            df.to_xlsx( fullDstName , index = index, mode = 'w', encoding = encoding )\n",
    "    else:\n",
    "        print('Please check your file path! Only, xlsx and csv can use')\n",
    "\n",
    "        \n",
    "def SubContents( targetUrl ):\n",
    "    \"\"\"\n",
    "    SubContents\n",
    "    #News address  = targetUrl\n",
    "    \"\"\"\n",
    "    try:\n",
    "        str = requests.get( targetUrl , headers={'User-Agent':'Mozilla/5.0'} )\n",
    "    except:\n",
    "        str = requests.get( targetUrl )\n",
    "    soup    = BeautifulSoup( str.text , 'lxml' ) # lxml ,html.parser\n",
    "    urlNew  = [i['href'] for i in soup.select( '.news .type01 li dt a')]\n",
    "    \n",
    "    return urlNew   \n",
    "    \n",
    "    \n",
    "    \n",
    "def Soup( targetUrl ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        str = requests.get( targetUrl , headers={'User-Agent':'Mozilla/5.0'} )\n",
    "    except:\n",
    "        str = requests.get( targetUrl )\n",
    "    soup    = BeautifulSoup( str.content , 'lxml' ) # lxml    \n",
    "    return soup   \n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "def Subtxt( targetUrl ):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        str = requests.get( targetUrl , headers={'User-Agent':'Mozilla/5.0'} )\n",
    "    except:\n",
    "        str = requests.get( targetUrl )\n",
    "    soup    = BeautifulSoup( str.content , 'lxml' ) # lxml   \n",
    "    cont    = [i.text for i in soup.select('#content')]\n",
    "    \n",
    "    return cont  \n",
    "\n",
    "\n",
    "def Subtxt( targetUrl ):\n",
    "    id_result = {'Code': ['content', 'article', 'CmAdContent']}\n",
    "    punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "    \"\"\"\n",
    "    \"\"\" \n",
    "    soup    = Soup(targetUrl) # func\n",
    "    \n",
    "    try:\n",
    "        for i in id_result['Code']:\n",
    "            cont    = [i.text for i in soup.select('#'+i)]\n",
    "            print(i)\n",
    "    except:\n",
    "        print('missUrl', targetUrl)\n",
    "    \n",
    "#     print(cont)\n",
    "    return cont \n",
    "    \n",
    "    \n",
    "###############################################################################\n",
    "        \n",
    "def PageUrl( txt, y, m, d, page ):\n",
    "    \"\"\"\n",
    "    # Page assignment\n",
    "    from urllib.parse import quote\n",
    "    page = '11 단위 수치정보' -> 11,21,31 이런식 \n",
    "    \"\"\"\n",
    "    keyword    = quote(txt)\n",
    "    mainUrl    = f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}'\n",
    "\n",
    "    if page == 1 :\n",
    "        #  page data\n",
    "        paramUrl  = f'&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&ds={y}.{m}.{d}&de={y}.{m}.{d}&docid=&nso=so%3Ar%2Cp%3Afrom{y}{m}{d}to{y}{m}{d}%2Ca%3Aall&mynews=0&refresh_start=0&related=0'\n",
    "        targetUrl = mainUrl + paramUrl\n",
    "        return targetUrl\n",
    "\n",
    "    else:\n",
    "        # Non-page data\n",
    "        paramUrl  = f'&sm=tab_pge&sort=0&photo=0&field=0&reporter_article=&pd=3&ds={y}.{m}.{d}&de={y}.{m}.{d}&docid=&nso=so:r,p:from{y}{m}{d}to{y}{m}{d},a:all&mynews=0&cluster_rank=32&start={page}&refresh_start=0'\n",
    "        targetUrl = mainUrl + paramUrl\n",
    "        return targetUrl\n",
    "\n",
    "\n",
    "    \n",
    "def BasicContents( targetUrl ):\n",
    "    \"\"\"\n",
    "    Lightly, 언론사 그리고 큐스 타이틀만 가지고 오기 \n",
    "    News address  = targetUrl\n",
    "    \"\"\"\n",
    "    try:\n",
    "        str = requests.get( targetUrl , headers={'User-Agent':'Mozilla/5.0'} )\n",
    "    except:\n",
    "        str = requests.get( targetUrl )\n",
    "    soup    = BeautifulSoup( str.text , 'lxml' ) # lxml\n",
    "\n",
    "    newsTitles = soup.select( '.news .type01 li dt a[title]' )\n",
    "    step       = soup.select( '.news .type01 li dd ._sp_each_source' )\n",
    "\n",
    "    cmpy = [ tit['title'] for tit in newsTitles ]          # 언론사 \n",
    "    txt  = [ s.text.split('언론사 선정')[0] for s in step] # 뉴스 타이틀\n",
    "    \n",
    "    return cmpy, txt   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MaxPageCunt( targetUrl ):\n",
    "    \"\"\"\n",
    "    import math \n",
    "    # Full viewable page  -> MaxPageCunt( target_url ) \n",
    "    \"\"\" \n",
    "    response = requests.get( targetUrl )\n",
    "    soup     = BeautifulSoup( response.text, 'lxml' )\n",
    "    \n",
    "    maxPages = soup.find('div',{'class':'title_desc all_my'}) # Total page  \n",
    "    \n",
    "    if maxPages != None:\n",
    "        maxPages = maxPages.find('span').text.split('/')[1].replace('건','').replace(',','').replace(' ','')\n",
    "        print('maxPages',maxPages )\n",
    "\n",
    "        # The number of items on the current page\n",
    "        CurrPagesStep = soup.find('div',{'class':'title_desc all_my'})\n",
    "        CurrPagesStep = CurrPagesStep.find('span').text.split('/')[0].split('-')[1].replace(' ','').replace(',','')\n",
    "\n",
    "        CurrPagesStep = int( CurrPagesStep )\n",
    "        TitPages      = int( maxPages )/4000   # Total Page -> More than 4000 fix it  \n",
    "\n",
    "        # Page count\n",
    "        if TitPages >= 1 :  # More than 4000  \n",
    "            maxPages = 4000\n",
    "            TitPages = int(int(maxPages)/10)\n",
    "\n",
    "        else: # 4000 or less \n",
    "            TitPages = math.ceil(int(maxPages)/10)\n",
    "        return CurrPagesStep, TitPages \n",
    "    \n",
    "    else:\n",
    "        CurrPagesStep = 0\n",
    "        TitPages      = 0\n",
    "        return CurrPagesStep, TitPages \n",
    "    \n",
    "     \n",
    "def StrDate(num):\n",
    "    \"\"\"\n",
    "    # date type change \n",
    "    \"\"\"\n",
    "    if num >= 10:\n",
    "        num = str(num)\n",
    "    else:\n",
    "        num = \"0\"+str(num)\n",
    "    return num\n",
    "\n",
    "\n",
    "def mkDir(pathName, fileName):\n",
    "    \"\"\"\n",
    "    pathName = 'C:/data/'      # 경로\n",
    "    fileName = '이름'          # 이름 \n",
    "    Save Folder Name = pathName, dirname\n",
    "    \"\"\"\n",
    "    path = pathName + fileName\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        targetDir = glob.glob(path)\n",
    "        print('Folder Created')\n",
    "    else:\n",
    "        targetDir = glob.glob(path)\n",
    "        print('Folder already exist')\n",
    "        \n",
    "    return path   \n",
    "\n",
    "def Main( y, m, d, txt, pathName, fileName):\n",
    "    \"\"\"\n",
    "    # 크롤링 메인 함수 - 1일 기준 \n",
    "    y = Year m = Month, d = Day, txt = Keyword, pathName = 파일 위치, fileName = output 될 메인파일이름 \n",
    "    output 파일은 이런 형식으로 {name}_{y}-{m}-{d}' \n",
    "    \"\"\"\n",
    "    page    = 1\n",
    "    dic     = {}\n",
    "    \n",
    "    mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "    \n",
    "    m = StrDate(m) # Date Type\n",
    "    d = StrDate(d)\n",
    "        \n",
    "    Running = True \n",
    "    while Running:\n",
    "        \n",
    "        \n",
    "        targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "        Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "        subUrl         = SubContents(targetUrl)\n",
    "        for u in subUrl:\n",
    "            dic['SubContent'] = Subtxt(u)\n",
    "        \n",
    "        CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "        print(targetUrl) \n",
    "        try:\n",
    "            Titles, Posts = BasicContents( targetUrl )\n",
    "        except:\n",
    "            Titles = 'NaN'\n",
    "            Posts  = 'NaN'\n",
    "\n",
    "        date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "        \n",
    "        dic['Title'] = Titles\n",
    "        dic['Post']  = Posts\n",
    "        dic['Date']  = date\n",
    "        \n",
    "        df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "        \n",
    "        fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "        SaveFile(df, fullDstName, 'a', False,  'euc-kr') # df, fullDstName,  Mode, index, encoding\n",
    "        print( '='*20, f'{page}','='*20 )\n",
    "        page += 10 \n",
    "        \n",
    "        #  종료 옵션 \n",
    "        if page == 4001 :  # Crawling max page 4000!\n",
    "            Running = False\n",
    "        elif TitPages == 0 :\n",
    "            Running = False\n",
    "        elif page == (TitPages*10)+1:\n",
    "            Running = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def MergeData( pathName, fileName ):\n",
    "    \"\"\"\n",
    "    # 일단위로 저장 된 데이터를 병합 \n",
    "    import pandas as pd\n",
    "    import glob, os\n",
    "    pathName = 'C:/data/' \n",
    "    fileName = '이름'\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    dataList = list()\n",
    "    path = mkDir( pathName, fileName ) # Dir check func if Do not have dir make it!\n",
    "    \n",
    "    for pth in tqdm(glob.glob( path +'/*')):\n",
    "        origin  = pd.read_csv( pth, index_col = False )\n",
    "        cnt = cnt + len(origin)\n",
    "        dataList.append(origin)\n",
    "        \n",
    "    CatList= pd.concat( dataList, axis=0, ignore_index = True )\n",
    "    # data folder dir  Save csv file\n",
    "    fullDstName =  path +'.csv'\n",
    "    SaveFile(CatList, fullDstName,'w', False, 'euc-kr')\n",
    "#     SaveFile(CatList, fullDstName,'w', False, 'utf-8-sig')\n",
    "    newPath = glob.glob(pathName+'/*')\n",
    "    print(cnt)\n",
    "    \n",
    "    return newPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, glob, time, math\n",
    "import pandas as pd\n",
    "\n",
    "# 크롤링\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathName = 'C:/TmP/' # 사용자가 원하는 경로\n",
    "fileName     = 'test' \n",
    "txt          = '사회문제' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "d = 1\n",
    "y = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exist\n",
      "http://www.daejonilbo.com/news/newsitem.asp?pk_no=1403370\n",
      "http://yna.kr/AKR20200101039051074?did=1195m\n",
      "http://www.newstown.co.kr/news/articleView.html?idxno=441159\n",
      "http://www.newsis.com/view/?id=NISX20200101_0000876769&cID=10301&pID=10300\n",
      "https://news.joins.com/article/olink/23265605\n",
      "http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202001012036005&code=990100\n",
      "http://www.newsis.com/view/?id=NISX20200101_0000876813&cID=10101&pID=10100\n",
      "http://it.chosun.com/site/data/html_dir/2019/12/31/2019123101951.html\n",
      "http://www.ddaily.co.kr/news/article.html?no=190161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.edaily.co.kr/news/newspath.asp?newsid=01236566625633456\n",
      "maxPages 220\n",
      "https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EC%82%AC%ED%9A%8C%EB%AC%B8%EC%A0%9C&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&ds=2020.01.01&de=2020.01.01&docid=&nso=so%3Ar%2Cp%3Afrom20200101to20200101%2Ca%3Aall&mynews=0&refresh_start=0&related=0\n",
      "==================== 1 ====================\n",
      "http://www.hani.co.kr/arti/area/honam/922777.html\n",
      "https://news.joins.com/article/olink/23265605\n",
      "http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202001012036005&code=990100\n",
      "http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202001012035005&code=990100\n",
      "http://www.donga.com/news/article/all/20200101/99036397/1\n",
      "https://www.nocutnews.co.kr/news/5265815\n",
      "https://www.hankyung.com/politics/article/2020010159067\n",
      "http://www.ddaily.co.kr/news/article.html?no=190161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.edaily.co.kr/news/newspath.asp?newsid=01236566625633456\n",
      "http://www.newstown.co.kr/news/articleView.html?idxno=441159\n",
      "maxPages 206\n",
      "https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EC%82%AC%ED%9A%8C%EB%AC%B8%EC%A0%9C&sm=tab_pge&sort=0&photo=0&field=0&reporter_article=&pd=3&ds=2020.01.01&de=2020.01.01&docid=&nso=so:r,p:from20200101to20200101,a:all&mynews=0&cluster_rank=32&start=11&refresh_start=0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d4f1007d092d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SubContent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdic\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# 데이터 프레임 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mfullDstName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpathName\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'%s.csv'\u001b[0m\u001b[1;33m%\u001b[0m \u001b[1;34mf'{fileName}/{fileName}_{date}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 크롤링 메인 함수 - 1일 기준 \n",
    "y = Year m = Month, d = Day, txt = Keyword, pathName = 파일 위치, fileName = output 될 메인파일이름 \n",
    "output 파일은 이런 형식으로 {name}_{y}-{m}-{d}' \n",
    "\"\"\"\n",
    "page    = 1\n",
    "dic     = {}\n",
    "dic_sub = {}\n",
    "box=list()\n",
    "mkDir( pathName, fileName ) # 디렉토리 생성 \n",
    "\n",
    "m = StrDate(m) # Date Type\n",
    "d = StrDate(d)\n",
    "\n",
    "Running = True \n",
    "while Running:\n",
    "\n",
    "    targetUrl      = PageUrl( txt, y, m, d, page )       # targetUrl \n",
    "    Titles, Posts  = BasicContents( targetUrl )          # Title, Company name  \n",
    "    subUrl         = SubContents(targetUrl)\n",
    "    \n",
    "#     print(subUrl)\n",
    "    for u in subUrl:\n",
    "        print(u)\n",
    "        box.append(Subtxt(u))\n",
    "    dic_sub['SubContent'] = box\n",
    "\n",
    "    CurrPagesStep, TitPages  = MaxPageCunt( targetUrl )  # Each Count, Total Pages Count\n",
    "    print(targetUrl) \n",
    "    try:\n",
    "        Titles, Posts = BasicContents( targetUrl )\n",
    "    except:\n",
    "        Titles = 'NaN'\n",
    "        Posts  = 'NaN'\n",
    "\n",
    "    date = str(y)+'-'+str(m)+'-'+str(d)\n",
    "\n",
    "    dic['Title'] = Titles\n",
    "    dic['Post']  = Posts\n",
    "    dic['Date']  = date\n",
    "#     dic['SubContent'] = box\n",
    "    \n",
    "    df = pd.DataFrame( dic ) # 데이터 프레임 저장 \n",
    "\n",
    "    fullDstName = pathName+'%s.csv'% f'{fileName}/{fileName}_{date}'\n",
    "    SaveFile(df, fullDstName, 'a', False,  'utf-8-sig') # df, fullDstName,  Mode, index, encoding\n",
    "    print( '='*20, f'{page}','='*20 )\n",
    "    page += 10 \n",
    "\n",
    "    #  종료 옵션 \n",
    "    if page == 4001 :  # Crawling max page 4000!\n",
    "        Running = False\n",
    "    elif TitPages == 0 :\n",
    "        Running = False\n",
    "    elif page == (TitPages*10)+1:\n",
    "        Running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~“”·]'\n",
    "# re.sub(punc,'',p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SubContent': [[[]],\n",
       "  [[]],\n",
       "  [['']],\n",
       "  [['정치 >  정치일반\\n\\n\\n김정은, 신년사 처음 거르고 전원회의로 대체…\"충격요법\"(종합)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n작게\\n크게\\n\\n\\n\\n\\n\\n\\n등록 2020-01-01 19:13:21\\n\\n \\n\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t내부 결속 의도+미국에 대한 압박 차원용 관측\\r\\n엄중한 정세 속에서 이뤄진 나흘짜리 전원회의 탓\\r\\n전원회의 보고 형식과 내용은 신년사와 거의 비슷\\r\\n전문가 \"내부 다잡기 일환…상황 돌파 위한 목적\"\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n[서울=뉴시스]북한 노동신문은 \\'조선로동당 중앙위원회 제7기 제5차 전원회의\\'에 관한 보도문과 함께 30여장의 사진과 함께 1일 인터넷판에 보도했다. (사진=노동신문 캡처) 2020.01.01.\\xa0 photo@newsis.com[서울=뉴시스] 박대로 김성진 기자 = 김정은 북한 국무위원장이 매년 1월1일 발표하던 육성 신년사를 거른 가운데 그 의도에 관심이 쏠린다.\\n\\r\\n김 위원장의 엄중한 상황 인식 속에서 북한 내부 결속 등의 차원에서 신년사를 노동당 전원회의로 대체하는 장면을 연출했다는 해석이 나온다.\\n\\r\\n북한 최고 지도자의 신년사는 북한 주민들에게 제시하는 국가 사업과 정책의 청사진으로 국가 운영에 있어 사실상 절대적인 지침이다.\\n\\r\\n김일성 주석이 지난 1946년 \"신년을 맞이하면서 전국 인민에게 고함\"이라는 제목의 첫 신년사를 발표한 이래 거의 매년 신년사가 발표되고 있다.\\n\\r\\n특히 김일성 주석 집권 시기에는 \\'종파사건\\'으로 신년사가 발표되지 않은 1957년과 노동신문 사설로 대체했던 1966~1968년과 1970년 그리고 최고인민회의 시정연설로 대체한 1987년을 제외하고 모두 육성 방송으로 신년사를 내보냈다.\\n\\r\\n김일성 주석이 말년에 접어든 1990년대에도 12월31일 집무실인 금수산태양궁전에서 당중앙위원회·중앙인민위원회·정무원(내각) 연합회의를 열고 신년사를 발표했다.\\n\\r\\n그러다 김정일 국방위원장 시대로 접어들면서 노동신문, 민주조선, 청년전위 등 3개 신문에 공동사설을 내는 방식으로 대체됐고 이같은 기조가 2011년까지 이어졌다.\\n\\n[서울=뉴시스]북한 노동신문은 \\'조선로동당 중앙위원회 제7기 제5차 전원회의\\'에 관한 보도문과 함께 30여장의 사진과 함께 1일 인터넷판에 보도했다. (사진=노동신문 캡처) 2020.01.01.\\xa0 photo@newsis.com김정은 위원장도 집권 첫해인 2012년에는 아버지 김정일 국방위원장의 상중임을 고려해 노동신문 공동사설 형태로 신년사를 했다.\\n\\r\\n이후 집권 2년차인 2013년부터 지난해까지는 매년 1월1일 녹화방송 형식의 육성 신년사가 조선중앙TV를 통해 발표됐다. 노동신문은 신년사 전문을 게재해왔다.\\n\\r\\n그러던 김 위원장이 올해는 나흘에 걸친 노동당 중앙위원회 전원회의 결과를 조선중앙통신과 조선중앙TV를 통해 보도하는 것으로 신년사를 대체했다.\\n\\r\\n올해 신년사를 전원회의로 대체한 것은 엄중한 상황 속에서 \\'이례적\\'으로 나흘간이나 진행된 당7기 5차 전원회의가 가장 큰 이유다.\\n\\r\\n전원회의가 지난달 28일부터 31일까지 이어지면서 새 전략노선을 담은 결정서 발표와 신년사 발표가 시기적으로 겹치게 됐다.\\n\\r\\n지난 1987년 할아버지인 김일성 주석도 최고인민회의 8기 1차회의 시정연설로 신년사를 대체한 전례가 있는 만큼, 전원회의 보고로 신년사를 갈음한 것으로 보인다.\\n\\n[서울=뉴시스]북한 노동신문은 \\'조선로동당 중앙위원회 제7기 제5차 전원회의\\'에 관한 보도문과 함께 30여장의 사진과 함께 1일 인터넷판에 보도했다. (사진=노동신문 캡처) 2020.01.01.\\xa0 photo@newsis.com다만 집권 이후 처음으로 신년사를 거른 셈이지만, 발표된 내용이나 그 구성은 신년사와 거의 유사했다.\\n\\r\\n김 위원장은 전원회의 보고를 통해 한 해 동안 달성할 정치, 군사, 경제, 사회 문제 등과 관련해 세밀한 그림까지 제시했다.\\n\\r\\n오히려 전원회의 보고 형태로 되면서 큰 방향성을 제시하는 신년사보다 당장 이행할 과업이나 개선할 문제가 더 선명해진 부분이 있다는 평가도 나온다.\\n\\r\\n조선중앙TV 보도 형식 역시 신년사를 의식한 듯 구성했다. \\n\\r\\n비록 김 위원장의 육성은 나오지 않았지만, 앵커가 김 위원장의 발언을 소개하면 통상 신년사 방송에서 위원장 발언에 맞춰 나오는 관련 사진들이 따라서 제시되기도 했다.\\n\\r\\n또 55분간 상영된 전원회의 방송은 대부분의 시간을 김 위원장의 발언 장면에 쏟았다.\\n\\n[서울=뉴시스]북한 노동신문은 \\'조선로동당 중앙위원회 제7기 제5차 전원회의\\'에 관한 보도문과 함께 30여장의 사진과 함께 1일 인터넷판에 보도했다. (사진=노동신문 캡처) 2020.01.01.\\xa0 photo@newsis.com아울러 이번에 신년사를 거른 목적이 내부 결속과 대미 메시지 발송 차원의 행보라는 해석도 나온다.\\n\\r\\n김용현 동국대 북한학과 교수는 뉴시스와 통화에서 \"전원회의에 600~700명이 참관하게 함으로써 지금의 엄중한 상황을 감안해 내부 다잡기를 한 것으로 보인다\"며 \"지금의 상황을 돌파하기 위한 노력을 요구하는 충격요법으로 읽힌다\"고 설명했다. \\n\\r\\n아울러 김 교수는 비핵화 협상에 엄중하게 임하고 있음을 미국에 보여주려는 의도도 있다고 봤다. 그는 \"성과가 없는 상태지만 미국이 적대시 정책을 포기하지 않으면서 손을 내밀지 않으면 올해 미국 대선 국면까지 우리가 버틸 수 있다는 것을 보여주려 한 듯하다\"고 분석했다.\\n\\r\\n일각에서는 김 위원장이 1인 독재 체제라는 인식을 불식시키기 위해 이 같은 모습을 연출하고 있다는 해석도 제기된다.\\n\\r\\n집권 이후 단상에 선 자세로 신년사를 발표하던 김 위원장은 지난해 노동당 중앙청사에서 양복 차림으로 소파에 앉아 신년사를 낭독하는 파격을 선보였다.\\n\\r\\n당시 이를 놓고 북한이 정상 국가를 지향한다는 이미지를 만들기 위한 연출이라는 해석이 나오기도 했다.\\n\\r\\n한편 북한은 신년사 발표 때와 마찬가지로 이번달부터 당 전원회의 결과를 주민들에게 교육하기 위한 군중대회 등을 이어갈 것으로 전망된다.\\n\\n\\n◎공감언론 뉴시스 daero@newsis.com, ksj87@newsis.com\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright © NEWSIS.COM, 무단 전재 및 재배포 금지 \\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n라이브리 댓글 작성을 위해 JavaScript를 활성화해주세요\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n이시간 핫 뉴스\\n\\n\\n\\n합의서에 서명하는 한정애·최대집\\n\\n\\n\\n\\n\\'황정음 이혼\\' 이영돈은 누구?…훈남 골퍼 출신 재력가\\n태국 왕실에 무슨 일이… 딸같은 후궁 내쳤다 복위시켜\\n이재명 \"변한 건 文대통령 눈빛이 아닌 안철수 눈빛\"\\n전광훈 \"문대통령, 나를 전광훈씨라고 부르며 모욕\"\\n\"한번에 천만원\" 성관계만 하고 도망…20대女 여럿 당해\\n김천서 잠자던 여고생 성폭행 파문…\"가해자 DNA 검출\"\\n\"코로나19 위험해!\"…문에 못질해 세 자녀 5개월 감금\\n소 6000마리 실은 배 침몰…선원 42명도 실종\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n오늘의 헤드라인\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t與-의협 합의문 서명…집단휴진 일단락\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t코로나 안정뒤 의대정원·공공의대 원점 재논의… 서명식 지연 한때 긴장\\t\\t\\t\\t\\t\\t\\t\\n더불어민주당과 대한의사협회(의협)는 4일 신종 코로나바이러스 감염증(코로나19) 안정화까지 의대정원 및 공공의대 확대 논의를 전면 중단하고 의료계도 집단휴진을 마치는 데 최종 합의\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n신규확진 198명, 200명 아래 턱걸이…국내 189명\\n\\n\\n\\n\\n\\n\\n\\n丁총리 \"거리두기 연장 논의…고삐 바짝 조여야\"\\n\\n\\n\\n\\n\\n\\n\\n7월 경상수지 9개월만에 최대…코로나 불황형 흑자\\n\\n\\n\\n\\n\\n\\n\\n코스피, 2.6% 급락 출발…나스닥 폭락 영향\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n메시 이적 해프닝?…\"바르샤 잔류 확률 90%\"\\n\\n\\n\\n\\n\\n\\n\\n로버트 패틴슨 확진…\\'배트맨\\' 촬영 중단\\n\\n\\n\\n\\n\\n\\n\\n코로나19 확산 방지 칸막이 점검\\n\\n\\n\\n\\n\\n\\n\\n추신수, 시즌 4호 홈런\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']],\n",
       "  [['\\n\\n\\n기자\\n\\n\\n\\n정종훈 기자\\n\\n\\n\\n\\n\\n신성식 기자\\n\\n\\n\\n\\n\\n김현예 기자\\n\\n\\n\\n\\n\\n이에스더 기자\\n\\n\\n\\n열기\\n\\n기자\\n\\n\\n\\n이은지 기자\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSNS 공유 및 댓글\\nSNS 클릭 수 102\\n카카오톡\\n페이스북\\n트위터\\n카카오스토리\\n\\nSNS 공유 더보기\\n\\n핀터레스트\\nURL 복사\\nSNS 공유 더보기 닫기\\n\\n\\n\\n\\n\\n     지난해 10월 서울 여의도 전경련 콘퍼런스센터에서 열린 \\'2019 중장년 희망 잡페어\\'를 찾은 중장년 구직자들이 이력서를 작성하고 있다. [연합뉴스]    신년기획-55년생 어쩌다 할배①\\xa0     727만6311명. 2018년 말 기준 1955~63년생 주민등록인구다. 9년에 걸쳐 태어난 \\'1차 베이비부머\\'는 65세 이상 노인(765만408명)과 맞먹을 정도다. 약 10년 뒤 지금의 노인과 비슷한 규모의 노인 집단이 더 생긴다는 의미다. 베이비부머 맏형격인 1955년생이 노인에 진입하는 올해가 인구 변화 \\'쓰나미\\'의 원년이다.\\xa0 올해 본격적인 인구 구조 변화 원년될 듯\"연금 등 고령화 문제, 미래형→현재진행형\"경제활동인구도 큰폭 감소 \"적극 대응 필요\"      전체 노인과 비슷한 베이비부머 규모. 그래픽=박경민 기자 minn@joongang.co.kr         55년생은 71만여명이다. 한 해 69만~92만명의 베이비부머가 2028년까지 차곡차곡 노인 세대로 진입한다. 일부 시·도에선 이미 지금의 노인 인구를 넘어섰다. 울산광역시 베이비부머는 16만8057명으로 전체 인구의 14.5%를 차지한다. 65세 이상 노인(12만3919명,10.7%)보다 4만여명 이상 많다. 인천과 대전, 세종, 경기도 비슷한 상황이다. 이들 지역은 앞으로 다른 곳보다 고령화의 짐을 더 짊어지게 된다.        일부 지역, 노인보다 베이비부머 많아. 그래픽=박경민 기자 minn@joongang.co.kr         의료비 증가, 건강보험료 인상, 더 내고 덜 받는 국민연금, 노인 빈곤 악화…. 베이비부머가 속속 노인이 되면서 인구 고령화에 따르는 사회적 문제들이 성큼 다가왔다. 조영태 서울대 보건대학원 교수는 \"지금껏 미래형에 가까웠던 고령화 문제가 올해부턴 현재진행형이 됐다. 지하철 무임승차 적자 폭 급증부터 시작해서 연금ㆍ의료비 등에서 오는 어려움이 국민 피부에 직접 와 닿게 될 거다\"고 말했다.        베이비부머 고령화, 앞으로가 더 문제. 그래픽=박경민 기자 minn@joongang.co.kr         베이비부머 발(發) 고령화는 당장 경제활동인구(15~64세)에서 커다란 구멍을 낸다. 1차 베이비부머가 빠져나가는 자리에 어린 2005~2013년생이 순차적으로 들어오게 된다. 하지만 이들을 다 합쳐도 418만145명에 그친다. 1차 베이비부머와 비교하면 310만명가량 적다. 저출산의 여파다. 여기에 더해 2차 베이비부머(1968~1974년생)도 13년 뒤부터 줄지어 노인 연령에 진입한다. 635만여명에 달하는 이들이 고령자가 되면 사회적 충격파가 배로 커진다.     \\xa0     최진호 아주대 사회학과 명예교수는 \"생산·소비를 활발히 할 인구가 줄면 경제 활력을 되찾기 어려워진다. 전반적으로 경제 성장률이 지금보다 더 떨어질 위험이 커졌다\"면서 \"향후 몇 년이 한국 사회에 미칠 영향은 매우 클 것\"이라고 했다.        지난해 12월 경기 수원시 영통구 수원컨벤션센터에서 열린 중장년 일자리 박람회 및 경기도 버스 승무사원 채용박람회를 찾은 구직자들이 일자리를 찾고 있다. [뉴스1]  관련기사어쩌다 할배 된 1955년생…내겐 청춘일 권리가 있다[어쩌다 할배 55년생]\"65세? 무릎 쑤시지만 나이트 가기 딱 좋은 나이\"\"일흔은 돼야 노인\" 경로석 손사래 치는 55년생  학계에선 정부가 지금이라도 베이비부머 고령화에 적극 대응해야 한다고 본다. 조영태 교수는 \"톱니바퀴처럼 맞물려 있는 정년 연장, 연금 개혁, 노인 연령 상향 문제를 다 같이 논의할 수밖에 없는 시점\"이라고 밝혔다. 최진호 교수는 \"정부가 출산율을 높이는 정책 드라이브를 거는 한편, 청년 일자리에 영향을 미치지 않는 수준에서 조심스레 정년 연장을 해야 한다\"고 제언했다.    \\xa0     ◇특별취재팀=신성식 복지전문기자, 김현예·이에스더·이은지·정종훈 기자 ssshin@joongang.co.kr  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJ팟\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n좋아요\\n22\\n\\n\\n싫어요\\n52\\n\\n\\n\\nSNS 공유\\n\\n\\n\\n\\n온라인 구독신청 지면 구독신청\\n\\n\\n\\n\\n\\n태그\\n\\n\\n\\n\\n#기획\\n\\n\\n#인구\\n\\n\\n#인구 구조\\n\\n\\n#이상 노인\\n\\n\\n#이들 베이비부머\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPHOTO & VIDEO\\n\\n\\n\\nPHOTO & VIDEO 더보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']],\n",
       "  [[]],\n",
       "  [['국제 >  국제일반\\n\\n\\n홍콩 새해 첫날 \\'100만\\' 시위...캐리 람, \\'일국양제\\' 재강조(종합)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n작게\\n크게\\n\\n\\n\\n\\n\\n\\n등록 2020-01-01 23:30:25\\n\\n \\n\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t캐리 람, 신년사서 \"겸허히 듣겠다\"면서도 일국양제 재확인\\r\\n도심 곳곳서 경찰·시위대 충돌...주최 측 \"100만 명 넘게 운집\"\\n\\n\\n[홍콩=AP/뉴시스]새해 첫날인 1일 홍콩 시내에서 대규모 민주화 요구 시위가 벌어지고 있다. 2020.01.01\\r\\n[런던=뉴시스] 이지예 기자 = 홍콩에서 새해 첫날부터 대규모 반정부 민주화 시위가 열렸다. 캐리 람 홍콩 행정장관은 장기화된 시위 사태를 책임지고 해결하겠다면서도 중국 일국양제(一國兩制· 한 국가 두 체제)의 중요성을 재차 강조했다. \\r\\n\\xa0\\r\\n1일 AP통신에 따르면 람 장관은 신년사를 통해 반정부 시위 장기화로 \"슬픔, 불안, 실망 심지어 분노가 조성됐다\"면서 \"우리 모두는 이 곤경이 끝나기를 바란다\"고 강조했다. \\r\\n\\xa0\\r\\n람 장관은 \"지난해 우리는 이전에 본 적 없는 도전들을 마주했다\"면서 새 해에는 홍콩의 사회경제적 문제를 해결하기 위해 노력하겠다고 밝혔다. \\r\\n\\xa0\\r\\n그는 경찰과 시위대의 극심한 충돌을 야기한 시위를 종식시키기 위해 겸허하게 목소리를 듣겠다면서도 일국양제 원칙의 중요성을 거듭 강조했다. \\r\\n\\xa0\\r\\n시진핑(習近平) 중국 국가주석 역시 전날 신년사에서 마카오의 사례는 일국양제가 전적으로 성취 가능하다는 사실을 보여준다며 홍콩 역시 같은 원칙 아래 번영과 안정을 이루길 바란다고 밝혔다. \\r\\n\\xa0\\r\\n홍콩에서는 중국으로의 \\'범죄인 인도법안(송환법)\\' 반대와 정부의 과도한 경찰력 투입을 규탄하는 반정부 민주화 시위가 작년 6월부터 수개월째 이어지고 있다. [홍콩=AP/뉴시스]새해 첫날인 1일 새벽 홍콩 시내에서 시위 참가자들이 경찰이 쏜 최루탄을 피해 달아나고 있다. 2020.01.01 \\r\\n새해 전야는 물론 신년 첫날에도 홍콩 도심 곳곳에서 대규모 시위가 열렸다. 일부 시위대와 경찰이 충돌하면서 극심한 혼돈이 빚어지기도 했다. \\r\\n\\xa0\\r\\n주최 측인 홍콩 민간인권전선(CHRF)은 이날 참가자가 100만 명 이상이었다며 작년 6월 9일 개최된 첫 번째 대규모 시위보다 인원이 많았다고 밝혔다고 사우스차이나모닝포스트(SCMP)가 보도했다. \\r\\n\\xa0\\r\\n시위대는 이날 빅토리아 파크에 집결한 뒤 코즈웨이 베이부터 차터로드까지 행진했다. 이들은 정부에 경찰 진압에 대한 독립 수사, 체포된 이들 사면, 보편적 참정권 등을 거듭 촉구했다. \\r\\n\\xa0\\r\\n일부 과격 시위대는 완차이, 코즈웨이베이 등에서 도로를 봉쇄하고 화염병과 쓰레기를 투척했다. HSBC은행 분점과 상점을 파손하기도 했다. 홍콩 고등법원 외벽에서 판사들을 비판하는 낙서도 발견됐다. \\n\\r\\n경찰은 최루가스와 물대포, 후추 스프레이 등으로 시위대 해산을 시도했다. SCMP는 경찰 소식통을 인용해 새해 첫날 400명 이상이 체포됐다고 보도했다.\\n\\n\\n◎공감언론 뉴시스 ez@newsis.com\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright © NEWSIS.COM, 무단 전재 및 재배포 금지 \\n\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n\\n\\n\\n관련기사\\n 새해 첫날 홍콩에서 대규모 민주화 요구 시위…전날엔 과격 시위도홍콩, 반정부 시위 속 새해 맞이...대규모 불꽃놀이 취소\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n라이브리 댓글 작성을 위해 JavaScript를 활성화해주세요\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n이시간 핫 뉴스\\n\\n\\n\\n합의서에 서명하는 한정애·최대집\\n\\n\\n\\n\\n\\'황정음 이혼\\' 이영돈은 누구?…훈남 골퍼 출신 재력가\\n태국 왕실에 무슨 일이… 딸같은 후궁 내쳤다 복위시켜\\n이재명 \"변한 건 文대통령 눈빛이 아닌 안철수 눈빛\"\\n전광훈 \"문대통령, 나를 전광훈씨라고 부르며 모욕\"\\n\"한번에 천만원\" 성관계만 하고 도망…20대女 여럿 당해\\n김천서 잠자던 여고생 성폭행 파문…\"가해자 DNA 검출\"\\n\"코로나19 위험해!\"…문에 못질해 세 자녀 5개월 감금\\n소 6000마리 실은 배 침몰…선원 42명도 실종\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n오늘의 헤드라인\\n\\n\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t與-의협 합의문 서명…집단휴진 일단락\\n\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t코로나 안정뒤 의대정원·공공의대 원점 재논의… 서명식 지연 한때 긴장\\t\\t\\t\\t\\t\\t\\t\\n더불어민주당과 대한의사협회(의협)는 4일 신종 코로나바이러스 감염증(코로나19) 안정화까지 의대정원 및 공공의대 확대 논의를 전면 중단하고 의료계도 집단휴진을 마치는 데 최종 합의\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n신규확진 198명, 200명 아래 턱걸이…국내 189명\\n\\n\\n\\n\\n\\n\\n\\n丁총리 \"거리두기 연장 논의…고삐 바짝 조여야\"\\n\\n\\n\\n\\n\\n\\n\\n7월 경상수지 9개월만에 최대…코로나 불황형 흑자\\n\\n\\n\\n\\n\\n\\n\\n코스피, 2.6% 급락 출발…나스닥 폭락 영향\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n메시 이적 해프닝?…\"바르샤 잔류 확률 90%\"\\n\\n\\n\\n\\n\\n\\n\\n로버트 패틴슨 확진…\\'배트맨\\' 촬영 중단\\n\\n\\n\\n\\n\\n\\n\\n코로나19 확산 방지 칸막이 점검\\n\\n\\n\\n\\n\\n\\n\\n추신수, 시즌 4호 홈런\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [['\\n\\n\\n기자\\n\\n\\n\\n정종훈 기자\\n\\n\\n\\n\\n\\n신성식 기자\\n\\n\\n\\n\\n\\n김현예 기자\\n\\n\\n\\n\\n\\n이에스더 기자\\n\\n\\n\\n열기\\n\\n기자\\n\\n\\n\\n이은지 기자\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSNS 공유 및 댓글\\nSNS 클릭 수 102\\n카카오톡\\n페이스북\\n트위터\\n카카오스토리\\n\\nSNS 공유 더보기\\n\\n핀터레스트\\nURL 복사\\nSNS 공유 더보기 닫기\\n\\n\\n\\n\\n\\n     지난해 10월 서울 여의도 전경련 콘퍼런스센터에서 열린 \\'2019 중장년 희망 잡페어\\'를 찾은 중장년 구직자들이 이력서를 작성하고 있다. [연합뉴스]    신년기획-55년생 어쩌다 할배①\\xa0     727만6311명. 2018년 말 기준 1955~63년생 주민등록인구다. 9년에 걸쳐 태어난 \\'1차 베이비부머\\'는 65세 이상 노인(765만408명)과 맞먹을 정도다. 약 10년 뒤 지금의 노인과 비슷한 규모의 노인 집단이 더 생긴다는 의미다. 베이비부머 맏형격인 1955년생이 노인에 진입하는 올해가 인구 변화 \\'쓰나미\\'의 원년이다.\\xa0 올해 본격적인 인구 구조 변화 원년될 듯\"연금 등 고령화 문제, 미래형→현재진행형\"경제활동인구도 큰폭 감소 \"적극 대응 필요\"      전체 노인과 비슷한 베이비부머 규모. 그래픽=박경민 기자 minn@joongang.co.kr         55년생은 71만여명이다. 한 해 69만~92만명의 베이비부머가 2028년까지 차곡차곡 노인 세대로 진입한다. 일부 시·도에선 이미 지금의 노인 인구를 넘어섰다. 울산광역시 베이비부머는 16만8057명으로 전체 인구의 14.5%를 차지한다. 65세 이상 노인(12만3919명,10.7%)보다 4만여명 이상 많다. 인천과 대전, 세종, 경기도 비슷한 상황이다. 이들 지역은 앞으로 다른 곳보다 고령화의 짐을 더 짊어지게 된다.        일부 지역, 노인보다 베이비부머 많아. 그래픽=박경민 기자 minn@joongang.co.kr         의료비 증가, 건강보험료 인상, 더 내고 덜 받는 국민연금, 노인 빈곤 악화…. 베이비부머가 속속 노인이 되면서 인구 고령화에 따르는 사회적 문제들이 성큼 다가왔다. 조영태 서울대 보건대학원 교수는 \"지금껏 미래형에 가까웠던 고령화 문제가 올해부턴 현재진행형이 됐다. 지하철 무임승차 적자 폭 급증부터 시작해서 연금ㆍ의료비 등에서 오는 어려움이 국민 피부에 직접 와 닿게 될 거다\"고 말했다.        베이비부머 고령화, 앞으로가 더 문제. 그래픽=박경민 기자 minn@joongang.co.kr         베이비부머 발(發) 고령화는 당장 경제활동인구(15~64세)에서 커다란 구멍을 낸다. 1차 베이비부머가 빠져나가는 자리에 어린 2005~2013년생이 순차적으로 들어오게 된다. 하지만 이들을 다 합쳐도 418만145명에 그친다. 1차 베이비부머와 비교하면 310만명가량 적다. 저출산의 여파다. 여기에 더해 2차 베이비부머(1968~1974년생)도 13년 뒤부터 줄지어 노인 연령에 진입한다. 635만여명에 달하는 이들이 고령자가 되면 사회적 충격파가 배로 커진다.     \\xa0     최진호 아주대 사회학과 명예교수는 \"생산·소비를 활발히 할 인구가 줄면 경제 활력을 되찾기 어려워진다. 전반적으로 경제 성장률이 지금보다 더 떨어질 위험이 커졌다\"면서 \"향후 몇 년이 한국 사회에 미칠 영향은 매우 클 것\"이라고 했다.        지난해 12월 경기 수원시 영통구 수원컨벤션센터에서 열린 중장년 일자리 박람회 및 경기도 버스 승무사원 채용박람회를 찾은 구직자들이 일자리를 찾고 있다. [뉴스1]  관련기사어쩌다 할배 된 1955년생…내겐 청춘일 권리가 있다[어쩌다 할배 55년생]\"65세? 무릎 쑤시지만 나이트 가기 딱 좋은 나이\"\"일흔은 돼야 노인\" 경로석 손사래 치는 55년생  학계에선 정부가 지금이라도 베이비부머 고령화에 적극 대응해야 한다고 본다. 조영태 교수는 \"톱니바퀴처럼 맞물려 있는 정년 연장, 연금 개혁, 노인 연령 상향 문제를 다 같이 논의할 수밖에 없는 시점\"이라고 밝혔다. 최진호 교수는 \"정부가 출산율을 높이는 정책 드라이브를 거는 한편, 청년 일자리에 영향을 미치지 않는 수준에서 조심스레 정년 연장을 해야 한다\"고 제언했다.    \\xa0     ◇특별취재팀=신성식 복지전문기자, 김현예·이에스더·이은지·정종훈 기자 ssshin@joongang.co.kr  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJ팟\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n좋아요\\n22\\n\\n\\n싫어요\\n52\\n\\n\\n\\nSNS 공유\\n\\n\\n\\n\\n온라인 구독신청 지면 구독신청\\n\\n\\n\\n\\n\\n태그\\n\\n\\n\\n\\n#기획\\n\\n\\n#인구\\n\\n\\n#인구 구조\\n\\n\\n#이상 노인\\n\\n\\n#이들 베이비부머\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPHOTO & VIDEO\\n\\n\\n\\nPHOTO & VIDEO 더보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [['\\n\\n\\n\\n[더 나은 100년을 준비합니다/청년, 꼰대를 말하다]\\r\\n<1> 청년 33인이 겪은 꼰대\\n《청년이 괴롭다. 꼰대, 그리고 꼰대문화 탓이다. 청년 2명 중 1명은 꼰대로 인한 정신적, 육체적 고통을 호소하고 있다. 피할 수도 없다. 직장이나 학교에서 일주일에2회 이상 그런 꼰대와 얼굴을 마주해야 한다.2020년 창간 100주년을 맞은 동아일보가 청년(15∼34세) 2020명에게 물어본 결과다.청년들은 꼰대를 조직과 사회의 활력을 잡아먹는 ‘바이러스’ 같은 존재로 여긴다. 새해 시대정신 중 하나는 ‘안티 꼰대’가 될 것이다. 하지만 꼰대가 정확히 무엇인지, 어떻게 우리 사회에 폐해를 끼치는지 진지한 고민이 없었다. 그저 공격과 비아냥거림의 대상이었다. 이제 동아일보는 청년 33인의 입을 통해 꼰대를 말하려 한다. 101년 전 민족대표 33인이 일제에 맞서 독립을 선언하듯 각계각층의 청년 33인이 꼰대로부터의 독립을 선언한다. 청년들의 선언은 기성세대를 흠집 내려는 것이 아니다. 무조건 단절을 원하지도 않는다. 세대의 벽을 넘어 서로를 이해함으로써 함께 통합의 길을 만들자는 것이다. 그러기 위해 “꼰대가 왜 싫은지 우리의 말을 한 번만 들어 달라”는 간절한 호소다. 33인의 청년은 다음과 같이 외친다.“꼰대 말고 어른이 돼주세요. 청년들도 당신의 후배이자 친구입니다.”》경희대 힙합동아리 ‘래빈’ 소속 청년들이 지난해 12월 24일 서울 강남구 선릉로의 ‘토끼굴’에서 ‘굿바이 꼰대’ 그라피티를 그리고 있다. 상단 가운데의 ‘라떼는 말이야’는 “나 때는 말이야”를 자주 이야기하는 꼰대들의 어투를 풍자한 것이다. 송은석 silverstone@donga.com “나는 왜 신분증 확인을 안 하냐?” 편의점에 들어와 담배를 계산대 위에 올려놓은 40대 중년 외모의 남성이 따지듯 물었다. “안 봐도 될 것 같아서요.” 아르바이트생 김태연 양(17)이 말했다. 그러자 남성은 “나 너보다 어려. 왜 확인을 안 하냐”며 언성을 높였다.  반말은 기본, 말도 안 되는 트집을 잡는 손님이 김 양 앞에 끊이지 않는다. 신용카드나 현금을 ‘휙’ 던지거나 진열대에서 물건을 가져다 달라며 서빙을 시키는 사람도 있다. “편의점 알바를 하기 전엔 몰랐어요. 이런 사람들이 진짜 많다는 걸. 대한민국을 뜨고 싶다는 생각까지 할 정도라면 믿어 주실래요?” ○ 갈수록 ‘진화하는’ 한국의 꼰대문화\\n\\n\\n\\n 박혜리(22) 이우진 씨(21·이상 고려대)가 만든 ‘금꼰’ 포스터(왼쪽 사진)는 영화 ‘82년생 김지영’의 포스터를 패러디해 꼰대 상사에게 시달리는 직장인의 모습을 재치 있게 드러냈다. 전영한 기자 scoopjyh@donga.com꼰대독립선언에 참여한 청년 33인은 우리 사회의 꼰대문화가 심각함을 넘어 ‘신박한(새롭고 놀랍다는 뜻)’ 정도라고 입을 모았다. 청년들은 ‘꼰대질’이 개인 성품의 문제가 아니라 사회 구조적 문제이며, 기성세대가 청년들을 억누르는 도구로 기능한다고 지적했다.\\n주요기사\\n\\n민주·의협 “원점 재검토” 합의문 서명…집단휴진 일단락‘코로나19’ 신규확진 198명이틀째 100명대 유지\\n\\n 개그 유튜버 이강 씨(24)는 개그동아리 선배들과 술집에 갔던 어느 날을 잊을 수 없다. 한 선배가 물을 먹다가 유머 하나를 소개했는데, 이 씨는 잘 알아듣지 못해 웃지 않았다. “이 유머를 몰라?” 고성과 함께 이 씨는 선배가 뿌린 물을 뒤집어썼다. ‘갑분싸’(갑자기 분위기가 싸해짐)의 순간, 다른 선배 한 명이 스스로 자신의 얼굴에 물을 뿌리며 콩트를 이어갔다. 겨우 분위기가 반전됐다. “개그를 할 사람은 분위기를 잘 맞춰야지. 선배가 물을 뿌리면 ‘아이스버킷 챌린지, 감사합니다!’라고 애드리브라도 쳐라. 그럼 분위기가 다시 좋아지지 않겠니?” 이 씨를 위기에서 구해준 선배가 충고했다. 하지만 그 말에 이 씨는 더욱 절망했다. “후배가 선배가 돼서 똑같이 꼰대질을 반복하는 구조라면 이런 일은 절대 사라지지 않을 것 같아요.” 한국 직장에는 꼰대가 유달리 많다. A 씨(26·여)는 지위 고하를 막론한 꼰대질에 지쳤다. “언제 결혼할 거냐”는 질문이 아무 때나 날아들고, 부장은 “애 낳고 싶지 않아?”라는 질문을 아무렇지 않게 던진다.  “애 낳고 싶은 생각 딱히 없는데요?”(A 씨) “왜? 애 낳으면 얼마나 좋은데.”(부장) “일단 저는 아파서 싫어요.”(A 씨) 이때 돌아온 부장의 대답이 압권이다. “아니야. 하나도 안 아파. 내 와이프는 제왕절개했더니 하나도 안 아팠대.” 배정미 씨(30·여)의 전 직장 상사는 타인의 ‘쇼핑 리스트’에 관심이 많았다. 배 씨가 온라인으로 주문한 책을 보더니 상사는 “다 읽기는 해? 그냥 장식으로 시키는 거 아냐”라고 따지듯 물었다. 책 구입은 엉뚱하게도 결혼 문제로 번지기도 한다. 상사는 “그렇게 돈을 써 대면 결혼을 못 한다. 남자들은 돈 많이 쓰는 여자들 안 좋아한다”고 훈계했다. 당시 상사의 직급은 대리, 나이는 배 씨보다 약간 많았다. 배 씨는 그를 ‘젊은 꼰대’라고 생각한다. 조가비 씨(33·여)는 미혼모라는 사실을 숨기지 않는다. 그때마다 돌아오는 건 “부모님 속상하시겠다” “효도 많이 해라” 같은 죄인 취급이다. “우리 엄마가 괜찮다는데 갑자기 제가 죄인이 되는 거죠.”○ 글로벌 기준으로 보면 꼰대질은 ‘범죄’ 이정인(23) 박하영 씨(23·이상 중앙대), 한수민 씨(21·한신대)가 만든 금꼰 포스터는 새해를 맞아 ‘꼰대가 되지 말자’는 다짐을 담았다.흔한 꼰대질이 글로벌 기준에서는 ‘범죄 수준’인 경우도 있다. 방송인 요아킴 소렌센 씨(29)는 “얼굴이 주먹만 하다”는 얘기를 많이 듣는다. 한국의 어느 집단이나 이런 ‘얼평’(얼굴 평가), ‘몸평’(몸매 평가) 문화가 만연한 것에 그는 큰 충격을 받았다. 소렌센 씨는 “스웨덴에서는 살쪘다는 말은 절대 하면 안 되고, 만약 못생겼다는 말까지 한다면 경찰에 신고할 수도 있다”고 지적했다.  광고회사를 퇴직한 배준영 씨(30·여)는 꼰대질이 타인에 대한 배려가 결여된 말과 행동을 일컫는다고 해석했다. 그렇다면 청년들은 꼰대들에게 어떤 말부터 하고 싶을까. “너는 꼰대로 태어난 게 아냐. 언젠가는 약자였어. 시키지만 말고 잘 들어주고 존중과 배려 좀 하자. 반말로 해야 할 것 같아 반말로 했다!”  ▼ ‘굿바이 꼰대’ 그라피티, ‘68년생 김부장’ 포스터… 대학생들과 협업 제작 ▼동아일보 창간 100주년 기획 ‘청년, 꼰대를 말하다’는 다양한 청년과의 컬래버레이션으로 완성됐다. 이들은 남다른 재능과 소통 방식으로 2030 청년기자가 주축인 본보 특별취재팀과 협업했다.  ‘굿바이 꼰대’ 그라피티는 경희대 힙합동아리 청년들의 작품. 이들은 그라피티 스폿으로 유명한 서울 강남구 선릉로의 일명 ‘토끼굴’에서 작업했다.  ‘금꼰 포스터’는 대학생 연합 광고동아리 학생들이 만들었다. 가정과 학교 직장 등에서 나타나는 여러 유형의 꼰대를 패러디한 것. ‘금연’하듯 ‘금꼰’하자는 메시지를 담았다. 앞으로 금꼰 포스터는 매회 주제에 맞춰 차례로 공개될 예정이다. ※당신이 만난 꼰대에 관한 경험담을 동아일보 특별취재팀 이메일(kkondae@donga.com)로 보내주세요. 꼰대들에게 전하고 싶은 건의, 부탁, 제언 등도 좋습니다. 여러분의 이야기를 기다립니다. 특별취재팀(가나다순)김소영 김수연 남건우 신규진 유성열 이윤태 조윤경 한성희 기자창닫기기사를 추천 하셨습니다다짜고짜 반말에 얼평-몸평까지… 꼰대에 절망하는 청년들베스트 추천 뉴스[김순덕 칼럼]정권비리 콕 찍어 알려준 추미애의 검찰인사“文대통령 뭐가 잘못?” 정청래에…김근식 “난독증이세요?”북한 북부 국경에서 벌어진 잔혹한 학살극[주성하 기자의 서울과 평양 사이]특검, ‘댓글조작’ 김경수 2심서 징역 6년 구형…선고는 11월 6일[이기홍 칼럼]제 무덤 파기 될 文정권의 ‘코로나 책임전가’[단독]드루킹 댓글 90만개 모두 조사한 특검 “文비판 댓글 0.7%”Copyright by dongA.com All rights reserved. #동아일보 창간 100주년#꼰대문화#청년\\n\\n\\n청년, 꼰대를 말하다“훈수-옛날얘기에 남의 인생 오지랖까지… 좀 참아주세요”교수평가하는 학생들, 갑질 대응나선 배달기사… ‘안티꼰대’ 뜬다다짜고짜 반말에 얼평-몸평까지… 꼰대에 절망하는 청년들\\n카카오톡페이스북트위터공유하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0 개의 기사의견이 있습니다.댓글쓰기\\nCopyright ⓒ 동아일보 & donga.com\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n당신이 좋아할 만한 콘텐츠\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n사회 많이 본 뉴스1‘거리두기 2.5단계’ 연장여부 오늘 11시 발표2추미애 아들 의혹제기 당직사병 “당시 軍유선전화로 통화”38m 파도 덮친 임원항… 상가 쑥대밭4與·의협 합의 서명식 1시간째 지연…전공의 반발 진통 겪나5‘코로나19’ 신규확진 198명…이틀째 100명대 유지6다수의견 8명 “법외노조 통보 법률근거 없어”, 반대의견 2명 “법체계 흠결 없어”7현대차, 베이징으로 전세기 3대 띄운다8丁총리 “수도권 거리두기 연장안 논의…다시 인내 부탁”9방역 위해 적은 내 개인정보, 아무나 다 본다10“누가 사진 찍으면 어쩌려고…” 수기 명부, 개인정보 무방비 노출\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n기사 의견\\n총 0개의 기사의견이 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [[]],\n",
       "  [['']]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-21-3370c6b0525b>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-3370c6b0525b>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    cont    = [i.text for i in soup.select('#'+i)]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def Subtxt( targetUrl ):\n",
    "    id_result = {'Code': ['content', 'article', 'CmAdContent']}\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        str = requests.get( targetUrl , headers={'User-Agent':'Mozilla/5.0'} )\n",
    "    except:\n",
    "        str = requests.get( targetUrl )\n",
    "    soup    = BeautifulSoup( str.content , 'html.parser' ) # lxml  \n",
    "    \n",
    "    try:\n",
    "        for i in id_result['Code']:\n",
    "        cont    = [i.text for i in soup.select('#'+i)]\n",
    "        print(i)\n",
    "    except:\n",
    "        print('missUrl',targetUrl)\n",
    "    \n",
    "    print(cont)\n",
    "    return cont  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_result= {}\n",
    "dm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Code': ['content', 'article', 'CmAdContent']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content\n",
      "article\n",
      "CmAdContent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_result['Code']= dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxPages 219\n",
      "https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EC%82%AC%ED%9A%8C%EB%AC%B8%EC%A0%9C&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=3&ds=2020.01.01&de=2020.01.01&docid=&nso=so%3Ar%2Cp%3Afrom20200101to20200101%2Ca%3Aall&mynews=0&refresh_start=0&related=0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-15d6359405c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mMain\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileName\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-bfbf3b0bd63f>\u001b[0m in \u001b[0;36mMain\u001b[1;34m(y, m, d, txt, pathName, fileName)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdic\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# 데이터 프레임 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mfullDstName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpathName\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'%s.csv'\u001b[0m\u001b[1;33m%\u001b[0m \u001b[1;34mf'{fileName}/{fileName}_{date}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# path =  pathName +  dirPath[0] + \"/\" \n",
    "# pathName = 'C:/data/'  # 사용자 임의\n",
    "# 변수 : 사용자 설정 \n",
    "fileName     = 'test' \n",
    "txt          = '사회문제' \n",
    "start_month  = 1\n",
    "end_month    = 1\n",
    "year         = 2020\n",
    "\n",
    "# mkDir( pathName, fileName )   #  폴더 생성 만약 있으면 pass\n",
    "\n",
    "# 기간 + 크롤링(전체 기간을 돌리는 경우 break 제거해야합니다.)\n",
    "thirtyOne = [1,3,5,7,8,10,12] \n",
    "for mth in range(start_month, end_month+1):\n",
    "    if mth == 2 : # 2월 \n",
    "        for dt in range(1,30):\n",
    "            Main( year, mth, dt, txt, pathName, fileName ) # 크롤링 코드 1일 \n",
    "            break\n",
    "    elif mth not in thirtyOne : \n",
    "        for dt in range(1,31):\n",
    "            Main( year, mth, dt, txt, pathName, fileName )\n",
    "            break\n",
    "    else:\n",
    "        for dt in range(1,32):\n",
    "            Main( year, mth, dt, txt, pathName, fileName )\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = SubContents(targetUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.donga.com/news/article/all/20200902/102750395/1\n",
      "http://www.fnnews.com/news/202009011747032336\n",
      "http://www.jbnews.com/news/articleView.html?idxno=1304965\n",
      "http://www.inews24.com/view/1295321\n",
      "https://www.news1.kr/articles/?4045882\n",
      "http://star.mk.co.kr/new/view.php?mc=ST&year=2020&no=905412\n",
      "http://www.breaknews.com/752724\n",
      "http://www.newswatch.kr/news/articleView.html?idxno=50774\n",
      "https://platum.kr/archives/147802\n",
      "http://www.kukinews.com/newsView/kuk202008310170\n"
     ]
    }
   ],
   "source": [
    "for i in SubContents(targetUrl):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.donga.com/news/article/all/20200902/102750395/1'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
