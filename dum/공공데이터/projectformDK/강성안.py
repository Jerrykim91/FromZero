# -*- coding: utf-8 -*-
"""Untitled9.ipynb의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x8jBE3wZ411tDprBCXpBT6DyOLS2l9YZ
"""

from google.colab import files
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

uploaded = files.upload()
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))

import pandas as pd
import io

data = pd.read_csv("data.csv", encoding='cp949')
data.info()
data = data.iloc[:,1:]
data.head(5)

x = data.iloc[:, 1:]
y = data.iloc[:,:1]

print(x.shape)
print(y.shape)
# y = target

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

mmsc = MinMaxScaler()
stsc = StandardScaler()

x = mmsc.fit_transform(x)
x = stsc.fit_transform(x)
y = mmsc.fit_transform(y)   # 머신러닝을 위한 정규화
y = stsc.fit_transform(y)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

from statsmodels.formula.api import ols

linear_reg = ols('pay_main ~ die + victim + area + pay_dis + pay_rec + tem_mean + tem_hi + tem_lo + rain + win_mean + win_max + win_ins', data=data).fit()
# linear_reg = ols('pay_main ~ die + win_mean + win_max + win_ins', data=data).fit()
linear_reg.summary()

from sklearn.linear_model import LinearRegression

reg_model = LinearRegression().fit(x_train, y_train)
reg_pred = np.expm1(reg_model.predict(x_test))
print("훈련 세트 정확도: {:.3f}".format(reg_model.score(x_train, y_train)))
print("테스트 세트 정확도: {:.3f}".format(reg_model.score(x_test, y_test)))

reg_pred=pd.DataFrame(reg_pred)
plt.plot(y_test, 'ro-', label="real")
plt.plot(reg_pred, 'bs-', label="predict")
plt.legend()
plt.title("Regression")
plt.show()

import xgboost as xgb

xgb = xgb.XGBRegressor(colsample_bytree=0.47,
                       gamma= 0.046,
                      learning_rate=0.05,
                      max_depth=5,
                      min_child_weight=1.8,
                      n_estimators=2000).fit(x_train, y_train)
xgb_pred = np.expm1(xgb.predict(x_test))
print("훈련 세트 정확도: {:.3f}".format(xgb.score(x_train, y_train)))
print("테스트 세트 정확도: {:.3f}".format(xgb.score(x_test, y_test)))
print(xgb.feature_importances_)

xgb_pred=pd.DataFrame(xgb_pred)
plt.plot(y_test, 'ro-', label="real")
plt.plot(xgb_pred, 'bs-', label="predict")
plt.legend()
plt.title("XGBoost")
plt.show()

from sklearn.svm import SVR

svr = SVR(C=1.5,
          cache_size=200,
          coef0=0,
          degree=15,
          kernel='rbf',
          shrinking=True).fit(x_train, y_train)

svr_pred = np.expm1(svr.predict(x_test))
print("훈련 세트 정확도: {:.3f}".format(svr.score(x_train, y_train)))
print("테스트 세트 정확도: {:.3f}".format(svr.score(x_test, y_test)))

svr_pred=pd.DataFrame(svr_pred)
plt.plot(y_test, 'ro-', label="real")
plt.plot(svr_pred, 'bs-', label="predict")
plt.legend()
plt.title("SVR")
plt.show()

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=2000).fit(x_train, y_train)

rf_pred = np.expm1(rf.predict(x_test))
print("훈련 세트 정확도: {:.3f}".format(rf.score(x_train, y_train)))
print("테스트 세트 정확도: {:.3f}".format(rf.score(x_test, y_test)))
print(rf.feature_importances_)

rf_pred=pd.DataFrame(rf_pred)
plt.plot(y_test, 'ro-', label="real")
plt.plot(rf_pred, 'bs-', label="predict")
plt.legend()
plt.title("RandomForest")
plt.show()

